{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":71552,"status":"ok","timestamp":1737212648231,"user":{"displayName":"Julius Maliwat","userId":"06100578401494245092"},"user_tz":-60},"id":"cL6F09cpvrtE","outputId":"2bbb80e9-fda1-4266-be3d-bd8a2ef64cd1"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-01-18 15:02:38--  https://www.kaggle.com/api/v1/datasets/download/ryanholbrook/cars196\n","Resolving www.kaggle.com (www.kaggle.com)... 35.244.233.98\n","Connecting to www.kaggle.com (www.kaggle.com)|35.244.233.98|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://storage.googleapis.com:443/kaggle-data-sets/629073/1120177/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20250118%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250118T150238Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=426a69951e3e9e1e66980130281898ea584d5bed0f4df82a3995ca23f78bbc9b430e59e1e64e4324753ccab6fcfc7ae6ebf8aaf82eef9b1cb84d7c6991e084810ee7c71084038e7c71a44a4dcc0a7f2e2643e32657fdcb6c284301eda7007072b876814ed635bb0d6a8c1312f15af9d9d742d5fb6cfc06c47be3e14adb9a600fe6374833f46f80ccd66c4e1519b8f03aa9beaa3bfcd22a6911fe02340bfac924fdb4c4e949239ef81cec00bdebf05003f48f9f6a3839675ffe16929dd44cb5649c025020cdbd119721a250bc7876639b57c60525416c3b64a4e73a1ebf9dfd9f96abbad2e86ce588823426d5b8604f5cc420676b944d1081656fb4145756bf66 [following]\n","--2025-01-18 15:02:38--  https://storage.googleapis.com/kaggle-data-sets/629073/1120177/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20250118%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250118T150238Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=426a69951e3e9e1e66980130281898ea584d5bed0f4df82a3995ca23f78bbc9b430e59e1e64e4324753ccab6fcfc7ae6ebf8aaf82eef9b1cb84d7c6991e084810ee7c71084038e7c71a44a4dcc0a7f2e2643e32657fdcb6c284301eda7007072b876814ed635bb0d6a8c1312f15af9d9d742d5fb6cfc06c47be3e14adb9a600fe6374833f46f80ccd66c4e1519b8f03aa9beaa3bfcd22a6911fe02340bfac924fdb4c4e949239ef81cec00bdebf05003f48f9f6a3839675ffe16929dd44cb5649c025020cdbd119721a250bc7876639b57c60525416c3b64a4e73a1ebf9dfd9f96abbad2e86ce588823426d5b8604f5cc420676b944d1081656fb4145756bf66\n","Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.200.207, 173.194.64.207, 74.125.126.207, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.200.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1957230190 (1.8G) [application/zip]\n","Saving to: ‘cars196.zip’\n","\n","cars196.zip         100%[===================>]   1.82G  70.2MB/s    in 39s     \n","\n","2025-01-18 15:03:17 (48.5 MB/s) - ‘cars196.zip’ saved [1957230190/1957230190]\n","\n","Archive:  cars196.zip\n","  inflating: cars196/2.0.0/cars196-test.tfrecord-00000-of-00008  \n","  inflating: cars196/2.0.0/cars196-test.tfrecord-00001-of-00008  \n","  inflating: cars196/2.0.0/cars196-test.tfrecord-00002-of-00008  \n","  inflating: cars196/2.0.0/cars196-test.tfrecord-00003-of-00008  \n","  inflating: cars196/2.0.0/cars196-test.tfrecord-00004-of-00008  \n","  inflating: cars196/2.0.0/cars196-test.tfrecord-00005-of-00008  \n","  inflating: cars196/2.0.0/cars196-test.tfrecord-00006-of-00008  \n","  inflating: cars196/2.0.0/cars196-test.tfrecord-00007-of-00008  \n","  inflating: cars196/2.0.0/cars196-train.tfrecord-00000-of-00008  \n","  inflating: cars196/2.0.0/cars196-train.tfrecord-00001-of-00008  \n","  inflating: cars196/2.0.0/cars196-train.tfrecord-00002-of-00008  \n","  inflating: cars196/2.0.0/cars196-train.tfrecord-00003-of-00008  \n","  inflating: cars196/2.0.0/cars196-train.tfrecord-00004-of-00008  \n","  inflating: cars196/2.0.0/cars196-train.tfrecord-00005-of-00008  \n","  inflating: cars196/2.0.0/cars196-train.tfrecord-00006-of-00008  \n","  inflating: cars196/2.0.0/cars196-train.tfrecord-00007-of-00008  \n","  inflating: cars196/2.0.0/dataset_info.json  \n","  inflating: cars196/2.0.0/image.image.json  \n","  inflating: cars196/2.0.0/label.labels.txt  \n","Contents of the dataset folder: ['2.0.0']\n"]}],"source":["# Download the Cars196 dataset using wget\n","!wget https://www.kaggle.com/api/v1/datasets/download/ryanholbrook/cars196 -O cars196.zip\n","\n","# Unzip the dataset into the current directory\n","!unzip cars196.zip\n","\n","# Verify the contents of the extracted dataset folder\n","import os\n","\n","dataset_dir = \"cars196\"  # Path to the dataset folder\n","if os.path.exists(dataset_dir):\n","    print(\"Contents of the dataset folder:\", os.listdir(dataset_dir))\n","else:\n","    print(\"Dataset folder 'cars196' not found!\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"gwWGlSPvwdse","executionInfo":{"status":"ok","timestamp":1737212651870,"user_tz":-60,"elapsed":3641,"user":{"displayName":"Julius Maliwat","userId":"06100578401494245092"}}},"outputs":[],"source":["from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","\n","def knn_exact(test_embeddings, train_embeddings, k):\n","    # Compute cosine similarity\n","    similarity = cosine_similarity(test_embeddings, train_embeddings)\n","    # Get top-k indices for each query\n","    top_k_indices = np.argsort(-similarity, axis=1)[:, :k]\n","    return top_k_indices\n","\n","def precision_at_k(top_k_indices, test_labels, train_labels, k=5):\n","\n","    correct = 0\n","    for i, neighbors in enumerate(top_k_indices):\n","        relevant = np.sum(train_labels[neighbors] == test_labels[i])\n","        correct += relevant\n","    return correct / (len(test_labels) * k)\n","\n","def recall_at_k(top_k_indices, test_labels, train_labels, k=5):\n","\n","    correct = 0\n","    for i, neighbors in enumerate(top_k_indices):\n","        if test_labels[i] in train_labels[neighbors]:\n","            correct += 1  # Conta se almeno un vicino è corretto\n","    return correct / len(test_labels)  # Denominatore è il numero di query\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3928,"status":"ok","timestamp":1737212655794,"user":{"displayName":"Julius Maliwat","userId":"06100578401494245092"},"user_tz":-60},"id":"2y0ycT4-wDy7","outputId":"ac683a46-e3ad-425b-a4be-551cf0fcc352"},"outputs":[{"output_type":"stream","name":"stdout","text":["Datasets loaded and preprocessed successfully!\n"]}],"source":["import tensorflow as tf\n","\n","# Paths to the train and test TFRecord files\n","train_tfrecord_path = \"cars196/2.0.0/cars196-train.tfrecord-*-of-00008\"\n","test_tfrecord_path = \"cars196/2.0.0/cars196-test.tfrecord-*-of-00008\"\n","label_file_path = \"cars196/2.0.0/label.labels.txt\"\n","\n","# Load class labels from label.labels.txt\n","def load_class_labels(label_file_path):\n","    with open(label_file_path, \"r\") as file:\n","        labels = [line.strip() for line in file.readlines()]\n","    return labels\n","\n","class_labels = load_class_labels(label_file_path)\n","\n","# Function to parse TFRecord files\n","def parse_example(example):\n","    feature_description = {\n","        \"image\": tf.io.FixedLenFeature([], tf.string),\n","        \"label\": tf.io.FixedLenFeature([], tf.int64),\n","    }\n","    example = tf.io.parse_single_example(example, feature_description)\n","    image = tf.image.decode_jpeg(example[\"image\"], channels=3)\n","    label = tf.cast(example[\"label\"], tf.int32)  # Converte in int32\n","    return image, label\n","\n","\n","def preprocess_image(image, label):\n","    image = tf.image.resize(image, (224, 224))  # Resize to 224x224\n","    image = tf.cast(image, tf.float32) / 127.5 - 1.0  # Normalize to [-1, 1]\n","    return image, label\n","\n","\n","# Load and preprocess the training dataset\n","batch_size = 128\n","\n","# Step 1: Ensure deterministic file order\n","train_files = sorted(tf.io.gfile.glob(train_tfrecord_path))\n","test_files = sorted(tf.io.gfile.glob(test_tfrecord_path))\n","\n","# Step 2: Define the train dataset\n","train_dataset = tf.data.TFRecordDataset(train_files)\n","train_dataset = train_dataset.map(parse_example, num_parallel_calls=tf.data.AUTOTUNE)\n","train_dataset = train_dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","\n","# Optional shuffle with a seed for reproducibility\n","train_dataset = train_dataset.shuffle(1000, seed=42)  # Deterministic shuffle\n","\n","\n","# Step 3: Define the test dataset\n","test_dataset = tf.data.TFRecordDataset(test_files)\n","test_dataset = test_dataset.map(parse_example, num_parallel_calls=tf.data.AUTOTUNE)\n","test_dataset = test_dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","\n","\n","print(\"Datasets loaded and preprocessed successfully!\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10189,"status":"ok","timestamp":1737212665976,"user":{"displayName":"Julius Maliwat","userId":"06100578401494245092"},"user_tz":-60},"id":"Ov9t3QYUwNQO","outputId":"0978a13d-b804-416c-81aa-cf7f62f00701"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1HCGAzITc6FGHkf7tYnvGNmERsCmn31yW\n","To: /content/EfficientNetB0_ProxyLoss_128_Cars196_train_embeddings.npz\n","100% 4.20M/4.20M [00:00<00:00, 43.5MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1mEqugDrgFphwxAtyxoKmjjTCRKggREw7\n","To: /content/EfficientNetB0_ProxyLoss_128_Cars196_test_embeddings.npz\n","100% 4.15M/4.15M [00:00<00:00, 41.1MB/s]\n"]}],"source":["# Download training embeddings (128 dimensions) with Proxy Loss\n","!gdown 1HCGAzITc6FGHkf7tYnvGNmERsCmn31yW -O EfficientNetB0_ProxyLoss_128_Cars196_train_embeddings.npz\n","\n","# Download test embeddings (128 dimensions) with Proxy Loss\n","!gdown 1mEqugDrgFphwxAtyxoKmjjTCRKggREw7 -O EfficientNetB0_ProxyLoss_128_Cars196_test_embeddings.npz"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Ah-1cc-FwP0C","executionInfo":{"status":"ok","timestamp":1737212665976,"user_tz":-60,"elapsed":3,"user":{"displayName":"Julius Maliwat","userId":"06100578401494245092"}}},"outputs":[],"source":["import numpy as np\n","\n","# Load embeddings (128 dimensions) with Proxy Loss for train\n","train_data_proxy = np.load(\"EfficientNetB0_ProxyLoss_128_Cars196_train_embeddings.npz\")\n","train_embeddings_proxy = train_data_proxy[\"embeddings\"]\n","train_labels_proxy = train_data_proxy[\"labels\"]\n","\n","# Load embeddings (128 dimensions) with Proxy Loss for test\n","test_data_proxy = np.load(\"EfficientNetB0_ProxyLoss_128_Cars196_test_embeddings.npz\")\n","test_embeddings_proxy = test_data_proxy[\"embeddings\"]\n","test_labels_proxy = test_data_proxy[\"labels\"]"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15219,"status":"ok","timestamp":1737212681191,"user":{"displayName":"Julius Maliwat","userId":"06100578401494245092"},"user_tz":-60},"id":"UUs2FEGjyi20","outputId":"06461475-9e47-4880-e2f7-165d9fc66f1a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.4/321.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install gradio --quiet"]},{"cell_type":"markdown","metadata":{"id":"uuPgDm6x2x1L"},"source":["nice index: 2625, 5890, 6722\n","\n","bad index: 5005, 4360"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":626},"id":"WbAqhb8gwTWq","outputId":"c9c5fa79-fd21-4b25-bdb5-2f89d00f6b04"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://d5767ddd5dc147e218.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://d5767ddd5dc147e218.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}}],"source":["import gradio as gr\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import time\n","\n","# Function to rescale images from [-1, 1] to [0, 1] for visualization\n","def rescale_image(image):\n","    return (image + 1.0) / 2.0\n","\n","# Function to retrieve an image and its label from a dataset given an index\n","def get_image_and_label(dataset, index):\n","    dataset_iter = iter(dataset)\n","    for i, (image, label) in enumerate(dataset_iter):\n","        if i == index:\n","            return image.numpy(), label.numpy()\n","    raise IndexError(\"Index out of range.\")\n","\n","# Main retrieval function for the demo\n","def retrieval_demo(query_index, k):\n","    # Start timing the retrieval process\n","    start_time = time.time()\n","\n","    # Retrieve the embedding for the selected query image\n","    query_embedding = test_embeddings_proxy[query_index].reshape(1, -1)\n","    top_k_indices = knn_exact(query_embedding, train_embeddings_proxy, k)[0]\n","\n","    # End timing after retrieval\n","    retrieval_time = time.time() - start_time\n","\n","    # Retrieve the query image and its label\n","    query_image, query_label = get_image_and_label(test_dataset, query_index)\n","\n","    # Initialize the figure for vertical layout\n","    fig, ax = plt.subplots(k + 1, 1, figsize=(5, 3 * (k + 1)))  # Set vertical layout\n","    ax[0].imshow(rescale_image(query_image))\n","    ax[0].set_title(f\"Query\\nClass: {class_labels[query_label]}\")\n","    ax[0].axis(\"off\")\n","\n","    # Display top-K retrieved images in a vertical layout\n","    for i, idx in enumerate(top_k_indices):\n","        # Reload the training dataset to maintain consistency\n","        train_dataset = tf.data.TFRecordDataset(train_files)\n","        train_dataset = train_dataset.map(parse_example, num_parallel_calls=tf.data.AUTOTUNE)\n","        train_dataset = train_dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","        train_dataset = train_dataset.shuffle(1000, seed=42)  # Ensure deterministic shuffling\n","\n","        # Retrieve image and label\n","        retrieved_image, retrieved_label = get_image_and_label(train_dataset, idx)\n","        ax[i + 1].imshow(rescale_image(retrieved_image))\n","        title_color = \"green\" if retrieved_label == query_label else \"red\"\n","        ax[i + 1].set_title(f\"Retrieved {i + 1}\\nClass: {class_labels[retrieved_label]}\", color=title_color)\n","        ax[i + 1].axis(\"off\")\n","\n","    # Save the plot as an image\n","    plt.tight_layout()\n","    buf, size = fig.canvas.print_to_buffer()\n","    img = np.frombuffer(buf, dtype=np.uint8).reshape(size[1], size[0], 4)[:, :, :3]  # Use only RGB channels\n","    plt.close(fig)\n","\n","    # Return results: Only retrieval time (Precision@K removed)\n","    metrics_text = f\"Retrieval Time: {retrieval_time:.4f} seconds\"\n","    return img, metrics_text\n","\n","# Configure Gradio interface\n","demo = gr.Interface(\n","    fn=retrieval_demo,\n","    inputs=[\n","        gr.Slider(0, len(test_embeddings_proxy) - 1, step=1, label=\"Query Index\"),\n","        gr.Slider(1, 10, step=1, label=\"K (Top-K)\"),\n","    ],\n","    outputs=[\n","        gr.Image(label=\"Retrieval Results\"),\n","        gr.Text(label=\"Metrics\"),\n","    ],\n","    title=\"Image Retrieval Demo\",\n","    description=\"Select a query index and number of top-K results to visualize the image retrieval performance, including retrieval time.\",\n",")\n","\n","# Launch the demo\n","demo.launch(debug=True)\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOM7o0VVlki6LajNTQQsUtR"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}