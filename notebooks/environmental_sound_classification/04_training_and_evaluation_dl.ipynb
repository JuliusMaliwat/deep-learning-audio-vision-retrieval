{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPlAkddvrj3N1wvA2modfcy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OwBc5GQX0Exh","executionInfo":{"status":"ok","timestamp":1735058172960,"user_tz":-60,"elapsed":12725,"user":{"displayName":"Julius Maliwat","userId":"06100578401494245092"}},"outputId":"e6dca339-fe1f-4d1f-e959-67bc22194f97"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1ebHt0zq0m4jWxCox9vSajxZfKLPRFTSm\n","To: /content/yamnet_embeddings_esc50.npz\n","100%|██████████| 8.35M/8.35M [00:00<00:00, 17.7MB/s]"]},{"output_type":"stream","name":"stdout","text":["YAMNet - Embeddings shape: (2000, 1024)\n","YAMNet - Labels shape: (2000,)\n","YAMNet - Folds shape: (2000,)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["ttesttesimport gdown\n","import numpy as np\n","\n","# Scaricare gli embeddings di YAMNet\n","gdown.download(\"https://drive.google.com/uc?id=1ebHt0zq0m4jWxCox9vSajxZfKLPRFTSm\", \"yamnet_embeddings_esc50.npz\", quiet=False)\n","\n","# Caricare gli embeddings\n","yamnet_data = np.load(\"yamnet_embeddings_esc50.npz\")\n","yamnet_embeddings = yamnet_data['embeddings']  # Shape: (2000, 1024)\n","yamnet_labels = yamnet_data['labels']          # Shape: (2000,)\n","yamnet_folds = yamnet_data['folds']            # Shape: (2000,)\n","yamnet_categories = yamnet_data['categories']  # Optional, se incluso\n","\n","print(f\"YAMNet - Embeddings shape: {yamnet_embeddings.shape}\")\n","print(f\"YAMNet - Labels shape: {yamnet_labels.shape}\")\n","print(f\"YAMNet - Folds shape: {yamnet_folds.shape}\")\n"]},{"cell_type":"code","source":["import tensorflow_hub as hub\n","import tensorflow as tf\n","\n","# Load YAMNet model from TensorFlow Hub\n","yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n","\n","print(\"YAMNet model loaded successfully.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kio6nl9e2WCJ","executionInfo":{"status":"ok","timestamp":1735058200743,"user_tz":-60,"elapsed":27788,"user":{"displayName":"Julius Maliwat","userId":"06100578401494245092"}},"outputId":"598f4fb0-e60d-4261-ebbf-1de9459e79b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["YAMNet model loaded successfully.\n"]}]},{"cell_type":"code","source":["def build_fcnn(input_dim, num_classes):\n","    model = tf.keras.Sequential([\n","        # Primo layer\n","        tf.keras.layers.Input(shape=(input_dim,)),\n","        tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dropout(0.3),\n","\n","        # Secondo layer\n","        tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dropout(0.2),\n","\n","        # Terzo layer\n","        tf.keras.layers.Dense(128, activation='relu'),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dropout(0.2),\n","\n","        # Quarto layer\n","        tf.keras.layers.Dense(64, activation='relu'),\n","        tf.keras.layers.Dropout(0.1),\n","\n","        # Layer di output\n","        tf.keras.layers.Dense(num_classes, activation='softmax')\n","    ])\n","    model.compile(\n","        optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-5),\n","        loss='sparse_categorical_crossentropy',  # Usiamo sparse perché i label sono numerici interi\n","        metrics=['accuracy']\n","    )\n","    return model\n"],"metadata":{"id":"yW4UcEcFfUBn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","\n","# Imposta le liste per raccogliere le metriche\n","accuracy_scores = []\n","f1_scores = []\n","\n","# Dimensione degli embeddings e numero di classi\n","input_dim = yamnet_embeddings.shape[1]\n","num_classes = len(np.unique(yamnet_labels))\n","\n","# Training con i fold predefiniti\n","for fold in range(1, 6):\n","    print(f\"Training on fold {fold}...\")\n","\n","    # Re-inizializza il modello per ogni fold\n","    model = build_fcnn(input_dim, num_classes)\n","\n","    # Split tra train e test basato sui fold\n","    train_indices = yamnet_folds != fold\n","    test_indices = yamnet_folds == fold\n","\n","    X_train, X_test = yamnet_embeddings[train_indices], yamnet_embeddings[test_indices]\n","    y_train, y_test = yamnet_labels[train_indices], yamnet_labels[test_indices]\n","\n","    # Training del modello\n","\n","    model.fit(\n","        X_train, y_train,\n","        epochs=50,\n","        batch_size=32,\n","        validation_data=(X_test, y_test),\n","        verbose=2\n","    )\n","    # Valutazione sul fold corrente\n","    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n","    accuracy_scores.append(accuracy)\n","\n","    # Calcolo F1-score\n","    y_pred = model.predict(X_test).argmax(axis=1)  # Predizioni come classi\n","    f1 = f1_score(y_test, y_pred, average='weighted')  # F1-score pesato\n","    f1_scores.append(f1)\n","\n","    print(f\"Fold {fold} - Test Accuracy: {accuracy:.4f}\")\n","    print(f\"Fold {fold} - Test F1-Score: {f1:.4f}\")\n","\n","    # Salvataggio del modello per ogni fold\n","    model.save(f\"yamnet_fcnn_fold_{fold}_embeddings.keras\")\n","    print(f\"Model for fold {fold} saved.\")\n","\n","# Calcolo delle metriche medie\n","accuracy_mean = np.mean(accuracy_scores)\n","accuracy_std = np.std(accuracy_scores)\n","f1_mean = np.mean(f1_scores)\n","f1_std = np.std(f1_scores)\n","\n","# Stampa dei risultati medi\n","print(\"\\nYAMNet FCNN Evaluation Results:\")\n","print(f\"Mean Accuracy: {accuracy_mean:.4f} ± {accuracy_std:.4f}\")\n","print(f\"Mean F1-Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OGnnHKCWgQbH","executionInfo":{"status":"ok","timestamp":1735060034003,"user_tz":-60,"elapsed":104546,"user":{"displayName":"Julius Maliwat","userId":"06100578401494245092"}},"outputId":"618694a4-71cf-4a4c-e7bd-b131bb51edf0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training on fold 1...\n","Epoch 1/50\n","50/50 - 9s - 170ms/step - accuracy: 0.0319 - loss: 4.2102 - val_accuracy: 0.0675 - val_loss: 3.9463\n","Epoch 2/50\n","50/50 - 0s - 7ms/step - accuracy: 0.1050 - loss: 3.7354 - val_accuracy: 0.1875 - val_loss: 3.8035\n","Epoch 3/50\n","50/50 - 1s - 10ms/step - accuracy: 0.1637 - loss: 3.4869 - val_accuracy: 0.2700 - val_loss: 3.6121\n","Epoch 4/50\n","50/50 - 0s - 5ms/step - accuracy: 0.2612 - loss: 3.1715 - val_accuracy: 0.3850 - val_loss: 3.3647\n","Epoch 5/50\n","50/50 - 0s - 5ms/step - accuracy: 0.3187 - loss: 2.9949 - val_accuracy: 0.4600 - val_loss: 3.0857\n","Epoch 6/50\n","50/50 - 0s - 4ms/step - accuracy: 0.3725 - loss: 2.8041 - val_accuracy: 0.5075 - val_loss: 2.8092\n","Epoch 7/50\n","50/50 - 0s - 7ms/step - accuracy: 0.4256 - loss: 2.6172 - val_accuracy: 0.5450 - val_loss: 2.5621\n","Epoch 8/50\n","50/50 - 0s - 6ms/step - accuracy: 0.4619 - loss: 2.4801 - val_accuracy: 0.5750 - val_loss: 2.3317\n","Epoch 9/50\n","50/50 - 0s - 6ms/step - accuracy: 0.4975 - loss: 2.3200 - val_accuracy: 0.5875 - val_loss: 2.1865\n","Epoch 10/50\n","50/50 - 0s - 5ms/step - accuracy: 0.5200 - loss: 2.2225 - val_accuracy: 0.6075 - val_loss: 2.0245\n","Epoch 11/50\n","50/50 - 0s - 3ms/step - accuracy: 0.5769 - loss: 2.0847 - val_accuracy: 0.6150 - val_loss: 1.8911\n","Epoch 12/50\n","50/50 - 0s - 6ms/step - accuracy: 0.5919 - loss: 1.9807 - val_accuracy: 0.6325 - val_loss: 1.8264\n","Epoch 13/50\n","50/50 - 0s - 3ms/step - accuracy: 0.6119 - loss: 1.8924 - val_accuracy: 0.6600 - val_loss: 1.7103\n","Epoch 14/50\n","50/50 - 0s - 6ms/step - accuracy: 0.6319 - loss: 1.8110 - val_accuracy: 0.6475 - val_loss: 1.6501\n","Epoch 15/50\n","50/50 - 0s - 7ms/step - accuracy: 0.6363 - loss: 1.7406 - val_accuracy: 0.6575 - val_loss: 1.5976\n","Epoch 16/50\n","50/50 - 0s - 3ms/step - accuracy: 0.6694 - loss: 1.6329 - val_accuracy: 0.6675 - val_loss: 1.5277\n","Epoch 17/50\n","50/50 - 0s - 6ms/step - accuracy: 0.6681 - loss: 1.5816 - val_accuracy: 0.6725 - val_loss: 1.4987\n","Epoch 18/50\n","50/50 - 0s - 3ms/step - accuracy: 0.6687 - loss: 1.5435 - val_accuracy: 0.6775 - val_loss: 1.4391\n","Epoch 19/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7006 - loss: 1.4699 - val_accuracy: 0.6850 - val_loss: 1.4002\n","Epoch 20/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7125 - loss: 1.3972 - val_accuracy: 0.6975 - val_loss: 1.3690\n","Epoch 21/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7269 - loss: 1.3552 - val_accuracy: 0.7000 - val_loss: 1.3361\n","Epoch 22/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7287 - loss: 1.3396 - val_accuracy: 0.7025 - val_loss: 1.2933\n","Epoch 23/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7362 - loss: 1.2654 - val_accuracy: 0.7275 - val_loss: 1.2598\n","Epoch 24/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7425 - loss: 1.2244 - val_accuracy: 0.7050 - val_loss: 1.2370\n","Epoch 25/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7400 - loss: 1.2052 - val_accuracy: 0.7225 - val_loss: 1.1980\n","Epoch 26/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7625 - loss: 1.1472 - val_accuracy: 0.7150 - val_loss: 1.1661\n","Epoch 27/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7756 - loss: 1.0773 - val_accuracy: 0.7225 - val_loss: 1.1896\n","Epoch 28/50\n","50/50 - 0s - 4ms/step - accuracy: 0.7619 - loss: 1.1124 - val_accuracy: 0.7050 - val_loss: 1.1770\n","Epoch 29/50\n","50/50 - 0s - 5ms/step - accuracy: 0.7750 - loss: 1.0721 - val_accuracy: 0.7325 - val_loss: 1.1581\n","Epoch 30/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7862 - loss: 1.0498 - val_accuracy: 0.7250 - val_loss: 1.1512\n","Epoch 31/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7837 - loss: 1.0173 - val_accuracy: 0.7375 - val_loss: 1.0972\n","Epoch 32/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7919 - loss: 1.0033 - val_accuracy: 0.7300 - val_loss: 1.0986\n","Epoch 33/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8025 - loss: 0.9508 - val_accuracy: 0.7200 - val_loss: 1.1124\n","Epoch 34/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7900 - loss: 0.9590 - val_accuracy: 0.7300 - val_loss: 1.0771\n","Epoch 35/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8025 - loss: 0.9357 - val_accuracy: 0.7300 - val_loss: 1.0844\n","Epoch 36/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7937 - loss: 0.9111 - val_accuracy: 0.7350 - val_loss: 1.0547\n","Epoch 37/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8044 - loss: 0.8949 - val_accuracy: 0.7250 - val_loss: 1.0848\n","Epoch 38/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7962 - loss: 0.9003 - val_accuracy: 0.7400 - val_loss: 1.0278\n","Epoch 39/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8188 - loss: 0.8625 - val_accuracy: 0.7150 - val_loss: 1.0862\n","Epoch 40/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8138 - loss: 0.8298 - val_accuracy: 0.7475 - val_loss: 1.0177\n","Epoch 41/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8125 - loss: 0.8458 - val_accuracy: 0.7425 - val_loss: 1.0164\n","Epoch 42/50\n","50/50 - 0s - 4ms/step - accuracy: 0.8263 - loss: 0.8181 - val_accuracy: 0.7575 - val_loss: 1.0039\n","Epoch 43/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8388 - loss: 0.7601 - val_accuracy: 0.7550 - val_loss: 0.9856\n","Epoch 44/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8394 - loss: 0.7615 - val_accuracy: 0.7550 - val_loss: 1.0203\n","Epoch 45/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8275 - loss: 0.7638 - val_accuracy: 0.7550 - val_loss: 0.9999\n","Epoch 46/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8325 - loss: 0.7588 - val_accuracy: 0.7375 - val_loss: 1.0149\n","Epoch 47/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8444 - loss: 0.7465 - val_accuracy: 0.7400 - val_loss: 1.0137\n","Epoch 48/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8350 - loss: 0.7256 - val_accuracy: 0.7450 - val_loss: 0.9760\n","Epoch 49/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8369 - loss: 0.7217 - val_accuracy: 0.7500 - val_loss: 0.9636\n","Epoch 50/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8487 - loss: 0.7007 - val_accuracy: 0.7575 - val_loss: 0.9953\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n","Fold 1 - Test Accuracy: 0.7575\n","Fold 1 - Test F1-Score: 0.7552\n","Model for fold 1 saved.\n","Training on fold 2...\n","Epoch 1/50\n","50/50 - 7s - 134ms/step - accuracy: 0.0419 - loss: 4.2148 - val_accuracy: 0.0775 - val_loss: 3.9332\n","Epoch 2/50\n","50/50 - 1s - 24ms/step - accuracy: 0.1081 - loss: 3.7402 - val_accuracy: 0.1375 - val_loss: 3.8224\n","Epoch 3/50\n","50/50 - 0s - 3ms/step - accuracy: 0.1706 - loss: 3.4121 - val_accuracy: 0.2225 - val_loss: 3.6462\n","Epoch 4/50\n","50/50 - 0s - 3ms/step - accuracy: 0.2469 - loss: 3.1487 - val_accuracy: 0.3000 - val_loss: 3.3618\n","Epoch 5/50\n","50/50 - 0s - 6ms/step - accuracy: 0.3225 - loss: 2.9384 - val_accuracy: 0.3975 - val_loss: 3.1072\n","Epoch 6/50\n","50/50 - 0s - 3ms/step - accuracy: 0.3988 - loss: 2.7391 - val_accuracy: 0.4750 - val_loss: 2.8477\n","Epoch 7/50\n","50/50 - 0s - 3ms/step - accuracy: 0.4363 - loss: 2.5620 - val_accuracy: 0.5225 - val_loss: 2.5847\n","Epoch 8/50\n","50/50 - 0s - 3ms/step - accuracy: 0.5044 - loss: 2.3943 - val_accuracy: 0.5600 - val_loss: 2.3919\n","Epoch 9/50\n","50/50 - 0s - 4ms/step - accuracy: 0.5144 - loss: 2.2709 - val_accuracy: 0.5975 - val_loss: 2.2154\n","Epoch 10/50\n","50/50 - 0s - 4ms/step - accuracy: 0.5569 - loss: 2.1646 - val_accuracy: 0.6125 - val_loss: 2.0684\n","Epoch 11/50\n","50/50 - 0s - 3ms/step - accuracy: 0.5788 - loss: 2.0835 - val_accuracy: 0.6325 - val_loss: 1.9529\n","Epoch 12/50\n","50/50 - 0s - 6ms/step - accuracy: 0.5931 - loss: 1.9587 - val_accuracy: 0.6375 - val_loss: 1.8632\n","Epoch 13/50\n","50/50 - 0s - 3ms/step - accuracy: 0.6169 - loss: 1.8705 - val_accuracy: 0.6500 - val_loss: 1.7702\n","Epoch 14/50\n","50/50 - 0s - 6ms/step - accuracy: 0.6212 - loss: 1.8024 - val_accuracy: 0.6775 - val_loss: 1.7028\n","Epoch 15/50\n","50/50 - 0s - 6ms/step - accuracy: 0.6344 - loss: 1.7393 - val_accuracy: 0.6775 - val_loss: 1.6307\n","Epoch 16/50\n","50/50 - 0s - 3ms/step - accuracy: 0.6719 - loss: 1.6401 - val_accuracy: 0.6875 - val_loss: 1.6083\n","Epoch 17/50\n","50/50 - 0s - 3ms/step - accuracy: 0.6750 - loss: 1.5938 - val_accuracy: 0.6875 - val_loss: 1.5404\n","Epoch 18/50\n","50/50 - 0s - 4ms/step - accuracy: 0.6800 - loss: 1.5345 - val_accuracy: 0.7000 - val_loss: 1.4677\n","Epoch 19/50\n","50/50 - 0s - 4ms/step - accuracy: 0.6956 - loss: 1.4824 - val_accuracy: 0.7100 - val_loss: 1.4183\n","Epoch 20/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7044 - loss: 1.4130 - val_accuracy: 0.7125 - val_loss: 1.4221\n","Epoch 21/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7200 - loss: 1.3646 - val_accuracy: 0.7075 - val_loss: 1.3647\n","Epoch 22/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7200 - loss: 1.3502 - val_accuracy: 0.7225 - val_loss: 1.3612\n","Epoch 23/50\n","50/50 - 0s - 4ms/step - accuracy: 0.7275 - loss: 1.2910 - val_accuracy: 0.7300 - val_loss: 1.3386\n","Epoch 24/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7387 - loss: 1.2522 - val_accuracy: 0.7350 - val_loss: 1.2549\n","Epoch 25/50\n","50/50 - 0s - 7ms/step - accuracy: 0.7437 - loss: 1.2296 - val_accuracy: 0.7325 - val_loss: 1.2428\n","Epoch 26/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7444 - loss: 1.1930 - val_accuracy: 0.7350 - val_loss: 1.2101\n","Epoch 27/50\n","50/50 - 0s - 4ms/step - accuracy: 0.7581 - loss: 1.1447 - val_accuracy: 0.7350 - val_loss: 1.1893\n","Epoch 28/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7781 - loss: 1.1023 - val_accuracy: 0.7325 - val_loss: 1.1938\n","Epoch 29/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7706 - loss: 1.0867 - val_accuracy: 0.7500 - val_loss: 1.1467\n","Epoch 30/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7856 - loss: 1.0414 - val_accuracy: 0.7575 - val_loss: 1.0777\n","Epoch 31/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7613 - loss: 1.0475 - val_accuracy: 0.7400 - val_loss: 1.1230\n","Epoch 32/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7975 - loss: 0.9956 - val_accuracy: 0.7575 - val_loss: 1.0882\n","Epoch 33/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7944 - loss: 0.9861 - val_accuracy: 0.7700 - val_loss: 1.0547\n","Epoch 34/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7962 - loss: 0.9448 - val_accuracy: 0.7525 - val_loss: 1.0386\n","Epoch 35/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8044 - loss: 0.9206 - val_accuracy: 0.7625 - val_loss: 1.0383\n","Epoch 36/50\n","50/50 - 0s - 4ms/step - accuracy: 0.8019 - loss: 0.9338 - val_accuracy: 0.7600 - val_loss: 1.0130\n","Epoch 37/50\n","50/50 - 0s - 5ms/step - accuracy: 0.8069 - loss: 0.8908 - val_accuracy: 0.7500 - val_loss: 0.9946\n","Epoch 38/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8044 - loss: 0.9018 - val_accuracy: 0.7575 - val_loss: 0.9919\n","Epoch 39/50\n","50/50 - 0s - 7ms/step - accuracy: 0.8206 - loss: 0.8511 - val_accuracy: 0.7900 - val_loss: 0.9370\n","Epoch 40/50\n","50/50 - 0s - 5ms/step - accuracy: 0.8250 - loss: 0.8452 - val_accuracy: 0.7600 - val_loss: 0.9880\n","Epoch 41/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8175 - loss: 0.8563 - val_accuracy: 0.7650 - val_loss: 0.9432\n","Epoch 42/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8256 - loss: 0.8255 - val_accuracy: 0.7750 - val_loss: 1.0013\n","Epoch 43/50\n","50/50 - 0s - 4ms/step - accuracy: 0.8338 - loss: 0.8167 - val_accuracy: 0.7675 - val_loss: 0.9360\n","Epoch 44/50\n","50/50 - 0s - 4ms/step - accuracy: 0.8106 - loss: 0.8219 - val_accuracy: 0.7650 - val_loss: 0.9652\n","Epoch 45/50\n","50/50 - 0s - 5ms/step - accuracy: 0.8275 - loss: 0.8122 - val_accuracy: 0.7750 - val_loss: 0.9295\n","Epoch 46/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8288 - loss: 0.7955 - val_accuracy: 0.7650 - val_loss: 0.9495\n","Epoch 47/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8469 - loss: 0.7445 - val_accuracy: 0.7675 - val_loss: 0.9583\n","Epoch 48/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8456 - loss: 0.7412 - val_accuracy: 0.7850 - val_loss: 0.8993\n","Epoch 49/50\n","50/50 - 0s - 4ms/step - accuracy: 0.8363 - loss: 0.7397 - val_accuracy: 0.7850 - val_loss: 0.8723\n","Epoch 50/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8419 - loss: 0.7034 - val_accuracy: 0.7875 - val_loss: 0.9192\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n","Fold 2 - Test Accuracy: 0.7875\n","Fold 2 - Test F1-Score: 0.7933\n","Model for fold 2 saved.\n","Training on fold 3...\n","Epoch 1/50\n","50/50 - 7s - 145ms/step - accuracy: 0.0294 - loss: 4.3836 - val_accuracy: 0.0600 - val_loss: 3.9956\n","Epoch 2/50\n","50/50 - 0s - 3ms/step - accuracy: 0.0631 - loss: 3.9591 - val_accuracy: 0.1200 - val_loss: 3.8753\n","Epoch 3/50\n","50/50 - 0s - 3ms/step - accuracy: 0.1325 - loss: 3.5863 - val_accuracy: 0.1975 - val_loss: 3.6933\n","Epoch 4/50\n","50/50 - 0s - 6ms/step - accuracy: 0.2069 - loss: 3.3170 - val_accuracy: 0.3725 - val_loss: 3.4557\n","Epoch 5/50\n","50/50 - 0s - 3ms/step - accuracy: 0.2925 - loss: 3.0551 - val_accuracy: 0.4450 - val_loss: 3.1762\n","Epoch 6/50\n","50/50 - 0s - 6ms/step - accuracy: 0.3706 - loss: 2.8902 - val_accuracy: 0.5300 - val_loss: 2.9095\n","Epoch 7/50\n","50/50 - 0s - 6ms/step - accuracy: 0.4175 - loss: 2.6991 - val_accuracy: 0.5625 - val_loss: 2.6467\n","Epoch 8/50\n","50/50 - 0s - 6ms/step - accuracy: 0.4544 - loss: 2.5521 - val_accuracy: 0.5775 - val_loss: 2.4173\n","Epoch 9/50\n","50/50 - 0s - 3ms/step - accuracy: 0.4869 - loss: 2.4379 - val_accuracy: 0.6025 - val_loss: 2.2347\n","Epoch 10/50\n","50/50 - 0s - 6ms/step - accuracy: 0.5431 - loss: 2.3063 - val_accuracy: 0.6175 - val_loss: 2.0924\n","Epoch 11/50\n","50/50 - 0s - 3ms/step - accuracy: 0.5537 - loss: 2.1912 - val_accuracy: 0.6225 - val_loss: 1.9753\n","Epoch 12/50\n","50/50 - 0s - 6ms/step - accuracy: 0.5944 - loss: 2.0380 - val_accuracy: 0.6550 - val_loss: 1.8905\n","Epoch 13/50\n","50/50 - 0s - 3ms/step - accuracy: 0.5950 - loss: 2.0034 - val_accuracy: 0.6575 - val_loss: 1.8051\n","Epoch 14/50\n","50/50 - 0s - 3ms/step - accuracy: 0.6075 - loss: 1.9347 - val_accuracy: 0.6625 - val_loss: 1.7448\n","Epoch 15/50\n","50/50 - 0s - 6ms/step - accuracy: 0.6388 - loss: 1.8349 - val_accuracy: 0.6650 - val_loss: 1.6762\n","Epoch 16/50\n","50/50 - 0s - 3ms/step - accuracy: 0.6425 - loss: 1.7827 - val_accuracy: 0.6975 - val_loss: 1.6050\n","Epoch 17/50\n","50/50 - 0s - 3ms/step - accuracy: 0.6575 - loss: 1.6946 - val_accuracy: 0.6950 - val_loss: 1.5946\n","Epoch 18/50\n","50/50 - 0s - 6ms/step - accuracy: 0.6906 - loss: 1.6160 - val_accuracy: 0.6875 - val_loss: 1.5191\n","Epoch 19/50\n","50/50 - 0s - 3ms/step - accuracy: 0.6862 - loss: 1.5778 - val_accuracy: 0.7200 - val_loss: 1.5095\n","Epoch 20/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7106 - loss: 1.4741 - val_accuracy: 0.6950 - val_loss: 1.4545\n","Epoch 21/50\n","50/50 - 0s - 7ms/step - accuracy: 0.7119 - loss: 1.4627 - val_accuracy: 0.7225 - val_loss: 1.3884\n","Epoch 22/50\n","50/50 - 0s - 5ms/step - accuracy: 0.7188 - loss: 1.3777 - val_accuracy: 0.7050 - val_loss: 1.3695\n","Epoch 23/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7350 - loss: 1.3499 - val_accuracy: 0.7075 - val_loss: 1.3500\n","Epoch 24/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7281 - loss: 1.3268 - val_accuracy: 0.7275 - val_loss: 1.3045\n","Epoch 25/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7337 - loss: 1.3015 - val_accuracy: 0.7200 - val_loss: 1.3000\n","Epoch 26/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7500 - loss: 1.2364 - val_accuracy: 0.7475 - val_loss: 1.2481\n","Epoch 27/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7694 - loss: 1.1663 - val_accuracy: 0.7375 - val_loss: 1.2276\n","Epoch 28/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7781 - loss: 1.1661 - val_accuracy: 0.7625 - val_loss: 1.2060\n","Epoch 29/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7806 - loss: 1.1111 - val_accuracy: 0.7475 - val_loss: 1.1921\n","Epoch 30/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7756 - loss: 1.1031 - val_accuracy: 0.7775 - val_loss: 1.1735\n","Epoch 31/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7775 - loss: 1.0729 - val_accuracy: 0.7550 - val_loss: 1.1660\n","Epoch 32/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7713 - loss: 1.0652 - val_accuracy: 0.7825 - val_loss: 1.1601\n","Epoch 33/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7937 - loss: 1.0230 - val_accuracy: 0.7575 - val_loss: 1.1414\n","Epoch 34/50\n","50/50 - 0s - 4ms/step - accuracy: 0.7925 - loss: 0.9870 - val_accuracy: 0.7625 - val_loss: 1.1008\n","Epoch 35/50\n","50/50 - 0s - 4ms/step - accuracy: 0.8094 - loss: 0.9634 - val_accuracy: 0.7625 - val_loss: 1.1390\n","Epoch 36/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8069 - loss: 0.9434 - val_accuracy: 0.7575 - val_loss: 1.1104\n","Epoch 37/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8025 - loss: 0.9262 - val_accuracy: 0.7675 - val_loss: 1.0849\n","Epoch 38/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8200 - loss: 0.9006 - val_accuracy: 0.7750 - val_loss: 1.0496\n","Epoch 39/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8050 - loss: 0.9004 - val_accuracy: 0.7800 - val_loss: 1.0706\n","Epoch 40/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8294 - loss: 0.8636 - val_accuracy: 0.7725 - val_loss: 1.0810\n","Epoch 41/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8194 - loss: 0.8837 - val_accuracy: 0.7825 - val_loss: 1.0384\n","Epoch 42/50\n","50/50 - 0s - 8ms/step - accuracy: 0.8344 - loss: 0.8016 - val_accuracy: 0.7775 - val_loss: 1.0273\n","Epoch 43/50\n","50/50 - 0s - 5ms/step - accuracy: 0.8163 - loss: 0.8394 - val_accuracy: 0.7975 - val_loss: 1.0171\n","Epoch 44/50\n","50/50 - 0s - 5ms/step - accuracy: 0.8213 - loss: 0.8086 - val_accuracy: 0.7925 - val_loss: 0.9959\n","Epoch 45/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8294 - loss: 0.7879 - val_accuracy: 0.8075 - val_loss: 0.9756\n","Epoch 46/50\n","50/50 - 0s - 4ms/step - accuracy: 0.8338 - loss: 0.7857 - val_accuracy: 0.8100 - val_loss: 1.0151\n","Epoch 47/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8375 - loss: 0.7579 - val_accuracy: 0.8100 - val_loss: 0.9659\n","Epoch 48/50\n","50/50 - 0s - 5ms/step - accuracy: 0.8375 - loss: 0.7592 - val_accuracy: 0.7800 - val_loss: 1.0391\n","Epoch 49/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8419 - loss: 0.7434 - val_accuracy: 0.7950 - val_loss: 0.9866\n","Epoch 50/50\n","50/50 - 0s - 4ms/step - accuracy: 0.8388 - loss: 0.7360 - val_accuracy: 0.7900 - val_loss: 1.0235\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n","Fold 3 - Test Accuracy: 0.7900\n","Fold 3 - Test F1-Score: 0.7905\n","Model for fold 3 saved.\n","Training on fold 4...\n","Epoch 1/50\n","50/50 - 7s - 134ms/step - accuracy: 0.0381 - loss: 4.2594 - val_accuracy: 0.0625 - val_loss: 3.9467\n","Epoch 2/50\n","50/50 - 0s - 3ms/step - accuracy: 0.0794 - loss: 3.8096 - val_accuracy: 0.1325 - val_loss: 3.7981\n","Epoch 3/50\n","50/50 - 0s - 3ms/step - accuracy: 0.1600 - loss: 3.5186 - val_accuracy: 0.2275 - val_loss: 3.5911\n","Epoch 4/50\n","50/50 - 0s - 6ms/step - accuracy: 0.2375 - loss: 3.2093 - val_accuracy: 0.3700 - val_loss: 3.3196\n","Epoch 5/50\n","50/50 - 0s - 3ms/step - accuracy: 0.3169 - loss: 2.9776 - val_accuracy: 0.4750 - val_loss: 3.0287\n","Epoch 6/50\n","50/50 - 0s - 6ms/step - accuracy: 0.3756 - loss: 2.8074 - val_accuracy: 0.5600 - val_loss: 2.7317\n","Epoch 7/50\n","50/50 - 0s - 3ms/step - accuracy: 0.4425 - loss: 2.6271 - val_accuracy: 0.6050 - val_loss: 2.4518\n","Epoch 8/50\n","50/50 - 0s - 3ms/step - accuracy: 0.4981 - loss: 2.4374 - val_accuracy: 0.6325 - val_loss: 2.2361\n","Epoch 9/50\n","50/50 - 0s - 3ms/step - accuracy: 0.4981 - loss: 2.3521 - val_accuracy: 0.6375 - val_loss: 2.0649\n","Epoch 10/50\n","50/50 - 0s - 7ms/step - accuracy: 0.5387 - loss: 2.2218 - val_accuracy: 0.6425 - val_loss: 1.9217\n","Epoch 11/50\n","50/50 - 0s - 3ms/step - accuracy: 0.5644 - loss: 2.1526 - val_accuracy: 0.6600 - val_loss: 1.7899\n","Epoch 12/50\n","50/50 - 0s - 5ms/step - accuracy: 0.5806 - loss: 2.0308 - val_accuracy: 0.6900 - val_loss: 1.6897\n","Epoch 13/50\n","50/50 - 1s - 10ms/step - accuracy: 0.6044 - loss: 1.9410 - val_accuracy: 0.6925 - val_loss: 1.6186\n","Epoch 14/50\n","50/50 - 1s - 20ms/step - accuracy: 0.6156 - loss: 1.8806 - val_accuracy: 0.7075 - val_loss: 1.5588\n","Epoch 15/50\n","50/50 - 1s - 17ms/step - accuracy: 0.6212 - loss: 1.7980 - val_accuracy: 0.7000 - val_loss: 1.5001\n","Epoch 16/50\n","50/50 - 0s - 5ms/step - accuracy: 0.6463 - loss: 1.7189 - val_accuracy: 0.7125 - val_loss: 1.4267\n","Epoch 17/50\n","50/50 - 0s - 5ms/step - accuracy: 0.6625 - loss: 1.6135 - val_accuracy: 0.7175 - val_loss: 1.3934\n","Epoch 18/50\n","50/50 - 0s - 3ms/step - accuracy: 0.6731 - loss: 1.5779 - val_accuracy: 0.7275 - val_loss: 1.3427\n","Epoch 19/50\n","50/50 - 0s - 3ms/step - accuracy: 0.6712 - loss: 1.5686 - val_accuracy: 0.7275 - val_loss: 1.2972\n","Epoch 20/50\n","50/50 - 0s - 6ms/step - accuracy: 0.6906 - loss: 1.4900 - val_accuracy: 0.7175 - val_loss: 1.2728\n","Epoch 21/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7038 - loss: 1.4409 - val_accuracy: 0.7425 - val_loss: 1.2548\n","Epoch 22/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7038 - loss: 1.4312 - val_accuracy: 0.7500 - val_loss: 1.2035\n","Epoch 23/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7356 - loss: 1.3370 - val_accuracy: 0.7550 - val_loss: 1.1550\n","Epoch 24/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7281 - loss: 1.3116 - val_accuracy: 0.7475 - val_loss: 1.1633\n","Epoch 25/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7331 - loss: 1.2823 - val_accuracy: 0.7525 - val_loss: 1.1374\n","Epoch 26/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7381 - loss: 1.2541 - val_accuracy: 0.7700 - val_loss: 1.1078\n","Epoch 27/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7387 - loss: 1.2130 - val_accuracy: 0.7725 - val_loss: 1.0627\n","Epoch 28/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7462 - loss: 1.1940 - val_accuracy: 0.7725 - val_loss: 1.0667\n","Epoch 29/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7638 - loss: 1.1354 - val_accuracy: 0.7675 - val_loss: 1.0586\n","Epoch 30/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7650 - loss: 1.1090 - val_accuracy: 0.7725 - val_loss: 1.0379\n","Epoch 31/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7656 - loss: 1.0669 - val_accuracy: 0.7850 - val_loss: 0.9843\n","Epoch 32/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7731 - loss: 1.0792 - val_accuracy: 0.7850 - val_loss: 0.9706\n","Epoch 33/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7763 - loss: 1.0631 - val_accuracy: 0.7875 - val_loss: 0.9825\n","Epoch 34/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7806 - loss: 1.0237 - val_accuracy: 0.7775 - val_loss: 0.9751\n","Epoch 35/50\n","50/50 - 0s - 4ms/step - accuracy: 0.7962 - loss: 0.9599 - val_accuracy: 0.7850 - val_loss: 0.9451\n","Epoch 36/50\n","50/50 - 0s - 5ms/step - accuracy: 0.7875 - loss: 0.9646 - val_accuracy: 0.7750 - val_loss: 0.9906\n","Epoch 37/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7975 - loss: 0.9653 - val_accuracy: 0.7800 - val_loss: 0.9292\n","Epoch 38/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8006 - loss: 0.9333 - val_accuracy: 0.7975 - val_loss: 0.9272\n","Epoch 39/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7969 - loss: 0.9134 - val_accuracy: 0.7800 - val_loss: 0.9548\n","Epoch 40/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7975 - loss: 0.9299 - val_accuracy: 0.8000 - val_loss: 0.9162\n","Epoch 41/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8069 - loss: 0.8605 - val_accuracy: 0.8000 - val_loss: 0.9205\n","Epoch 42/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8106 - loss: 0.8639 - val_accuracy: 0.8150 - val_loss: 0.8732\n","Epoch 43/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8075 - loss: 0.8792 - val_accuracy: 0.7950 - val_loss: 0.9166\n","Epoch 44/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8175 - loss: 0.8251 - val_accuracy: 0.7950 - val_loss: 0.8953\n","Epoch 45/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8281 - loss: 0.7994 - val_accuracy: 0.7975 - val_loss: 0.8914\n","Epoch 46/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8156 - loss: 0.8212 - val_accuracy: 0.7950 - val_loss: 0.8653\n","Epoch 47/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8369 - loss: 0.7807 - val_accuracy: 0.8000 - val_loss: 0.8617\n","Epoch 48/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8256 - loss: 0.7776 - val_accuracy: 0.7900 - val_loss: 0.8921\n","Epoch 49/50\n","50/50 - 0s - 4ms/step - accuracy: 0.8256 - loss: 0.7772 - val_accuracy: 0.7950 - val_loss: 0.8515\n","Epoch 50/50\n","50/50 - 0s - 5ms/step - accuracy: 0.8381 - loss: 0.7523 - val_accuracy: 0.7825 - val_loss: 0.8796\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Fold 4 - Test Accuracy: 0.7825\n","Fold 4 - Test F1-Score: 0.7928\n","Model for fold 4 saved.\n","Training on fold 5...\n","Epoch 1/50\n","50/50 - 7s - 147ms/step - accuracy: 0.0300 - loss: 4.3854 - val_accuracy: 0.0425 - val_loss: 3.9200\n","Epoch 2/50\n","50/50 - 0s - 10ms/step - accuracy: 0.0606 - loss: 3.9241 - val_accuracy: 0.1025 - val_loss: 3.7904\n","Epoch 3/50\n","50/50 - 0s - 6ms/step - accuracy: 0.1269 - loss: 3.5561 - val_accuracy: 0.1750 - val_loss: 3.5993\n","Epoch 4/50\n","50/50 - 0s - 6ms/step - accuracy: 0.1994 - loss: 3.3122 - val_accuracy: 0.3075 - val_loss: 3.3624\n","Epoch 5/50\n","50/50 - 0s - 6ms/step - accuracy: 0.2944 - loss: 3.0481 - val_accuracy: 0.4600 - val_loss: 3.0694\n","Epoch 6/50\n","50/50 - 0s - 6ms/step - accuracy: 0.3619 - loss: 2.8637 - val_accuracy: 0.5200 - val_loss: 2.7959\n","Epoch 7/50\n","50/50 - 0s - 3ms/step - accuracy: 0.4062 - loss: 2.6815 - val_accuracy: 0.5575 - val_loss: 2.5406\n","Epoch 8/50\n","50/50 - 0s - 6ms/step - accuracy: 0.4500 - loss: 2.5505 - val_accuracy: 0.6125 - val_loss: 2.3100\n","Epoch 9/50\n","50/50 - 0s - 4ms/step - accuracy: 0.4956 - loss: 2.4109 - val_accuracy: 0.6425 - val_loss: 2.1195\n","Epoch 10/50\n","50/50 - 0s - 5ms/step - accuracy: 0.5219 - loss: 2.2812 - val_accuracy: 0.6625 - val_loss: 1.9699\n","Epoch 11/50\n","50/50 - 0s - 6ms/step - accuracy: 0.5487 - loss: 2.1722 - val_accuracy: 0.6675 - val_loss: 1.8702\n","Epoch 12/50\n","50/50 - 0s - 6ms/step - accuracy: 0.5700 - loss: 2.0826 - val_accuracy: 0.6700 - val_loss: 1.7570\n","Epoch 13/50\n","50/50 - 0s - 6ms/step - accuracy: 0.5962 - loss: 1.9741 - val_accuracy: 0.6925 - val_loss: 1.6727\n","Epoch 14/50\n","50/50 - 0s - 3ms/step - accuracy: 0.6069 - loss: 1.9288 - val_accuracy: 0.6975 - val_loss: 1.6371\n","Epoch 15/50\n","50/50 - 0s - 6ms/step - accuracy: 0.6313 - loss: 1.8330 - val_accuracy: 0.7025 - val_loss: 1.5703\n","Epoch 16/50\n","50/50 - 0s - 6ms/step - accuracy: 0.6500 - loss: 1.7254 - val_accuracy: 0.6925 - val_loss: 1.5066\n","Epoch 17/50\n","50/50 - 0s - 3ms/step - accuracy: 0.6556 - loss: 1.6929 - val_accuracy: 0.7175 - val_loss: 1.4465\n","Epoch 18/50\n","50/50 - 0s - 7ms/step - accuracy: 0.6669 - loss: 1.6173 - val_accuracy: 0.7300 - val_loss: 1.4033\n","Epoch 19/50\n","50/50 - 0s - 3ms/step - accuracy: 0.6994 - loss: 1.5520 - val_accuracy: 0.7350 - val_loss: 1.3938\n","Epoch 20/50\n","50/50 - 0s - 7ms/step - accuracy: 0.6900 - loss: 1.5094 - val_accuracy: 0.7200 - val_loss: 1.2910\n","Epoch 21/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7050 - loss: 1.4663 - val_accuracy: 0.7400 - val_loss: 1.2781\n","Epoch 22/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7019 - loss: 1.4228 - val_accuracy: 0.7650 - val_loss: 1.2371\n","Epoch 23/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7125 - loss: 1.3800 - val_accuracy: 0.7550 - val_loss: 1.2035\n","Epoch 24/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7319 - loss: 1.3120 - val_accuracy: 0.7600 - val_loss: 1.1829\n","Epoch 25/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7356 - loss: 1.2784 - val_accuracy: 0.7600 - val_loss: 1.1530\n","Epoch 26/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7531 - loss: 1.2392 - val_accuracy: 0.7600 - val_loss: 1.1383\n","Epoch 27/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7631 - loss: 1.1665 - val_accuracy: 0.7725 - val_loss: 1.0943\n","Epoch 28/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7669 - loss: 1.1671 - val_accuracy: 0.7775 - val_loss: 1.0955\n","Epoch 29/50\n","50/50 - 0s - 4ms/step - accuracy: 0.7600 - loss: 1.1404 - val_accuracy: 0.7650 - val_loss: 1.0824\n","Epoch 30/50\n","50/50 - 0s - 7ms/step - accuracy: 0.7794 - loss: 1.1050 - val_accuracy: 0.7800 - val_loss: 1.0681\n","Epoch 31/50\n","50/50 - 0s - 4ms/step - accuracy: 0.7775 - loss: 1.0683 - val_accuracy: 0.7825 - val_loss: 1.0506\n","Epoch 32/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7819 - loss: 1.0492 - val_accuracy: 0.7675 - val_loss: 1.0234\n","Epoch 33/50\n","50/50 - 0s - 5ms/step - accuracy: 0.7794 - loss: 1.0406 - val_accuracy: 0.7775 - val_loss: 1.0130\n","Epoch 34/50\n","50/50 - 0s - 5ms/step - accuracy: 0.7881 - loss: 0.9829 - val_accuracy: 0.8000 - val_loss: 0.9932\n","Epoch 35/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8025 - loss: 0.9503 - val_accuracy: 0.8075 - val_loss: 0.9813\n","Epoch 36/50\n","50/50 - 0s - 5ms/step - accuracy: 0.7950 - loss: 0.9624 - val_accuracy: 0.7875 - val_loss: 0.9780\n","Epoch 37/50\n","50/50 - 0s - 7ms/step - accuracy: 0.7962 - loss: 0.9361 - val_accuracy: 0.7900 - val_loss: 0.9823\n","Epoch 38/50\n","50/50 - 0s - 4ms/step - accuracy: 0.8256 - loss: 0.9047 - val_accuracy: 0.8000 - val_loss: 0.9699\n","Epoch 39/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8125 - loss: 0.8853 - val_accuracy: 0.7975 - val_loss: 0.9489\n","Epoch 40/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8138 - loss: 0.8578 - val_accuracy: 0.8075 - val_loss: 0.9572\n","Epoch 41/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8213 - loss: 0.8361 - val_accuracy: 0.7975 - val_loss: 0.9415\n","Epoch 42/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8206 - loss: 0.8272 - val_accuracy: 0.8125 - val_loss: 0.9412\n","Epoch 43/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8181 - loss: 0.8408 - val_accuracy: 0.8025 - val_loss: 0.9217\n","Epoch 44/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8388 - loss: 0.7948 - val_accuracy: 0.8200 - val_loss: 0.8966\n","Epoch 45/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8388 - loss: 0.7686 - val_accuracy: 0.8225 - val_loss: 0.9146\n","Epoch 46/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8250 - loss: 0.7906 - val_accuracy: 0.8150 - val_loss: 0.8753\n","Epoch 47/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8388 - loss: 0.7612 - val_accuracy: 0.7925 - val_loss: 0.9501\n","Epoch 48/50\n","50/50 - 0s - 4ms/step - accuracy: 0.8431 - loss: 0.7536 - val_accuracy: 0.8100 - val_loss: 0.8725\n","Epoch 49/50\n","50/50 - 0s - 5ms/step - accuracy: 0.8425 - loss: 0.7275 - val_accuracy: 0.8175 - val_loss: 0.8574\n","Epoch 50/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8537 - loss: 0.7281 - val_accuracy: 0.8175 - val_loss: 0.8901\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n","Fold 5 - Test Accuracy: 0.8175\n","Fold 5 - Test F1-Score: 0.8238\n","Model for fold 5 saved.\n","\n","YAMNet FCNN Evaluation Results:\n","Mean Accuracy: 0.7870 ± 0.0191\n","Mean F1-Score: 0.7911 ± 0.0218\n"]}]},{"cell_type":"code","source":["import gdown\n","import numpy as np\n","\n","# Scarica gli embeddings AST dal link di Google Drive\n","gdown.download(\"https://drive.google.com/uc?id=1HAghy-Oqqg2G03KYlnwdO6z32gZEZVL3\", \"ast_embeddings_esc50.npz\", quiet=False)\n","\n","# Carica il file .npz\n","ast_data = np.load(\"ast_embeddings_esc50.npz\")\n","ast_embeddings = ast_data['embeddings']  # Shape: (2000, D)\n","ast_labels = ast_data['labels']          # Shape: (2000,)\n","ast_folds = ast_data['folds']            # Shape: (2000,)\n","ast_categories = ast_data['categories']  # Optional, se incluso\n","\n","# Controlla le dimensioni dei dati\n","print(f\"AST - Embeddings shape: {ast_embeddings.shape}\")\n","print(f\"AST - Labels shape: {ast_labels.shape}\")\n","print(f\"AST - Folds shape: {ast_folds.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHenOh6xeQCe","executionInfo":{"status":"ok","timestamp":1735379611183,"user_tz":-60,"elapsed":5121,"user":{"displayName":"Julius Maliwat","userId":"06100578401494245092"}},"outputId":"59f52709-94f0-47a8-b86c-8abf06bcbc8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1HAghy-Oqqg2G03KYlnwdO6z32gZEZVL3\n","To: /content/ast_embeddings_esc50.npz\n","100%|██████████| 6.31M/6.31M [00:00<00:00, 54.7MB/s]"]},{"output_type":"stream","name":"stdout","text":["AST - Embeddings shape: (2000, 768)\n","AST - Labels shape: (2000,)\n","AST - Folds shape: (2000,)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","import tensorflow_hub as hub\n","import tensorflow as tf\n","\n","\n","# Liste per raccogliere le metriche\n","accuracy_scores = []\n","f1_scores = []\n","\n","# Dimensione degli embeddings e numero di classi\n","input_dim = ast_embeddings.shape[1]\n","num_classes = len(np.unique(ast_labels))\n","\n","# Training per i fold predefiniti\n","for fold in range(1, 6):\n","    print(f\"Training on fold {fold}...\")\n","\n","    # Re-inizializza il modello per ogni fold\n","    model = build_fcnn(input_dim, num_classes)\n","\n","    # Split tra train e test basato sui fold\n","    train_indices = ast_folds != fold\n","    test_indices = ast_folds == fold\n","\n","    X_train, X_test = ast_embeddings[train_indices], ast_embeddings[test_indices]\n","    y_train, y_test = ast_labels[train_indices], ast_labels[test_indices]\n","\n","    # Addestramento del modello\n","    model.fit(\n","        X_train, y_train,\n","        epochs=50,\n","        batch_size=32,\n","        validation_data=(X_test, y_test),\n","        verbose=2\n","    )\n","\n","    # Valutazione sul fold corrente\n","    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n","    accuracy_scores.append(accuracy)\n","\n","    # Calcolo F1-score\n","    y_pred = model.predict(X_test).argmax(axis=1)  # Predizioni come classi\n","    f1 = f1_score(y_test, y_pred, average='weighted')\n","    f1_scores.append(f1)\n","\n","    print(f\"Fold {fold} - Test Accuracy: {accuracy:.4f}\")\n","    print(f\"Fold {fold} - Test F1-Score: {f1:.4f}\")\n","\n","    # Salvataggio del modello per ogni fold\n","    model.save(f\"ast_fcnn_fold_{fold}_embeddings.keras\")\n","    print(f\"Model for fold {fold} saved.\")\n","\n","# Calcolo delle metriche medie\n","accuracy_mean = np.mean(accuracy_scores)\n","accuracy_std = np.std(accuracy_scores)\n","f1_mean = np.mean(f1_scores)\n","f1_std = np.std(f1_scores)\n","\n","# Stampa dei risultati medi\n","print(\"\\nAST FCNN Evaluation Results:\")\n","print(f\"Mean Accuracy: {accuracy_mean:.4f} ± {accuracy_std:.4f}\")\n","print(f\"Mean F1-Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mY8pDLAfeTOh","executionInfo":{"status":"ok","timestamp":1735124633891,"user_tz":-60,"elapsed":132496,"user":{"displayName":"Julius Maliwat","userId":"06100578401494245092"}},"outputId":"b0429e15-3b64-4e49-c192-5e9fd6d443dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training on fold 1...\n","Epoch 1/50\n","50/50 - 10s - 197ms/step - accuracy: 0.0362 - loss: 4.1804 - val_accuracy: 0.0525 - val_loss: 3.9048\n","Epoch 2/50\n","50/50 - 0s - 3ms/step - accuracy: 0.0913 - loss: 3.6811 - val_accuracy: 0.2050 - val_loss: 3.6459\n","Epoch 3/50\n","50/50 - 0s - 6ms/step - accuracy: 0.1963 - loss: 3.2571 - val_accuracy: 0.4025 - val_loss: 3.2820\n","Epoch 4/50\n","50/50 - 0s - 3ms/step - accuracy: 0.3231 - loss: 2.9343 - val_accuracy: 0.5700 - val_loss: 2.8873\n","Epoch 5/50\n","50/50 - 0s - 6ms/step - accuracy: 0.4187 - loss: 2.6391 - val_accuracy: 0.6825 - val_loss: 2.5137\n","Epoch 6/50\n","50/50 - 0s - 3ms/step - accuracy: 0.5069 - loss: 2.3604 - val_accuracy: 0.7625 - val_loss: 2.1141\n","Epoch 7/50\n","50/50 - 0s - 3ms/step - accuracy: 0.6000 - loss: 2.1323 - val_accuracy: 0.8275 - val_loss: 1.7905\n","Epoch 8/50\n","50/50 - 0s - 6ms/step - accuracy: 0.6612 - loss: 1.9337 - val_accuracy: 0.8425 - val_loss: 1.5510\n","Epoch 9/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7013 - loss: 1.7523 - val_accuracy: 0.8900 - val_loss: 1.3478\n","Epoch 10/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7575 - loss: 1.5844 - val_accuracy: 0.8950 - val_loss: 1.2094\n","Epoch 11/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7887 - loss: 1.4452 - val_accuracy: 0.9050 - val_loss: 1.0545\n","Epoch 12/50\n","50/50 - 0s - 4ms/step - accuracy: 0.8100 - loss: 1.3285 - val_accuracy: 0.9100 - val_loss: 0.9488\n","Epoch 13/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8406 - loss: 1.2263 - val_accuracy: 0.9250 - val_loss: 0.8657\n","Epoch 14/50\n","50/50 - 0s - 4ms/step - accuracy: 0.8569 - loss: 1.1217 - val_accuracy: 0.9175 - val_loss: 0.7820\n","Epoch 15/50\n","50/50 - 0s - 5ms/step - accuracy: 0.8544 - loss: 1.0418 - val_accuracy: 0.9250 - val_loss: 0.7305\n","Epoch 16/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8988 - loss: 0.9184 - val_accuracy: 0.9275 - val_loss: 0.6803\n","Epoch 17/50\n","50/50 - 0s - 7ms/step - accuracy: 0.8956 - loss: 0.8574 - val_accuracy: 0.9375 - val_loss: 0.6309\n","Epoch 18/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9069 - loss: 0.7988 - val_accuracy: 0.9325 - val_loss: 0.5917\n","Epoch 19/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8988 - loss: 0.7903 - val_accuracy: 0.9325 - val_loss: 0.5604\n","Epoch 20/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9156 - loss: 0.7215 - val_accuracy: 0.9375 - val_loss: 0.5375\n","Epoch 21/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9262 - loss: 0.6596 - val_accuracy: 0.9375 - val_loss: 0.5109\n","Epoch 22/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9306 - loss: 0.6123 - val_accuracy: 0.9350 - val_loss: 0.4970\n","Epoch 23/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9244 - loss: 0.5816 - val_accuracy: 0.9375 - val_loss: 0.4765\n","Epoch 24/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9344 - loss: 0.5497 - val_accuracy: 0.9275 - val_loss: 0.4645\n","Epoch 25/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9413 - loss: 0.5075 - val_accuracy: 0.9300 - val_loss: 0.4462\n","Epoch 26/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9563 - loss: 0.4839 - val_accuracy: 0.9325 - val_loss: 0.4235\n","Epoch 27/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9425 - loss: 0.4677 - val_accuracy: 0.9275 - val_loss: 0.4165\n","Epoch 28/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9563 - loss: 0.4287 - val_accuracy: 0.9350 - val_loss: 0.4083\n","Epoch 29/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9606 - loss: 0.4147 - val_accuracy: 0.9350 - val_loss: 0.3932\n","Epoch 30/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9606 - loss: 0.3914 - val_accuracy: 0.9375 - val_loss: 0.3902\n","Epoch 31/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9619 - loss: 0.3823 - val_accuracy: 0.9400 - val_loss: 0.3843\n","Epoch 32/50\n","50/50 - 0s - 7ms/step - accuracy: 0.9600 - loss: 0.3697 - val_accuracy: 0.9325 - val_loss: 0.3795\n","Epoch 33/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9700 - loss: 0.3423 - val_accuracy: 0.9350 - val_loss: 0.3672\n","Epoch 34/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9663 - loss: 0.3413 - val_accuracy: 0.9250 - val_loss: 0.3676\n","Epoch 35/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9731 - loss: 0.3048 - val_accuracy: 0.9300 - val_loss: 0.3540\n","Epoch 36/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9787 - loss: 0.3001 - val_accuracy: 0.9350 - val_loss: 0.3480\n","Epoch 37/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9712 - loss: 0.2980 - val_accuracy: 0.9350 - val_loss: 0.3394\n","Epoch 38/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9737 - loss: 0.2852 - val_accuracy: 0.9350 - val_loss: 0.3344\n","Epoch 39/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9831 - loss: 0.2693 - val_accuracy: 0.9400 - val_loss: 0.3441\n","Epoch 40/50\n","50/50 - 1s - 16ms/step - accuracy: 0.9756 - loss: 0.2768 - val_accuracy: 0.9350 - val_loss: 0.3441\n","Epoch 41/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9837 - loss: 0.2537 - val_accuracy: 0.9350 - val_loss: 0.3448\n","Epoch 42/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9837 - loss: 0.2439 - val_accuracy: 0.9375 - val_loss: 0.3344\n","Epoch 43/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9812 - loss: 0.2319 - val_accuracy: 0.9375 - val_loss: 0.3325\n","Epoch 44/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9850 - loss: 0.2253 - val_accuracy: 0.9400 - val_loss: 0.3333\n","Epoch 45/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9794 - loss: 0.2287 - val_accuracy: 0.9350 - val_loss: 0.3357\n","Epoch 46/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9787 - loss: 0.2249 - val_accuracy: 0.9350 - val_loss: 0.3307\n","Epoch 47/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9894 - loss: 0.2024 - val_accuracy: 0.9375 - val_loss: 0.3285\n","Epoch 48/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9887 - loss: 0.1971 - val_accuracy: 0.9350 - val_loss: 0.3372\n","Epoch 49/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9919 - loss: 0.1882 - val_accuracy: 0.9325 - val_loss: 0.3210\n","Epoch 50/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9856 - loss: 0.2043 - val_accuracy: 0.9400 - val_loss: 0.3238\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n","Fold 1 - Test Accuracy: 0.9400\n","Fold 1 - Test F1-Score: 0.9391\n","Model for fold 1 saved.\n","Training on fold 2...\n","Epoch 1/50\n","50/50 - 8s - 160ms/step - accuracy: 0.0325 - loss: 4.2966 - val_accuracy: 0.0275 - val_loss: 3.9282\n","Epoch 2/50\n","50/50 - 0s - 5ms/step - accuracy: 0.0894 - loss: 3.7409 - val_accuracy: 0.1075 - val_loss: 3.7634\n","Epoch 3/50\n","50/50 - 0s - 5ms/step - accuracy: 0.1600 - loss: 3.3571 - val_accuracy: 0.2275 - val_loss: 3.5041\n","Epoch 4/50\n","50/50 - 0s - 6ms/step - accuracy: 0.2769 - loss: 3.0073 - val_accuracy: 0.4075 - val_loss: 3.1278\n","Epoch 5/50\n","50/50 - 0s - 6ms/step - accuracy: 0.3531 - loss: 2.7400 - val_accuracy: 0.5850 - val_loss: 2.7289\n","Epoch 6/50\n","50/50 - 0s - 4ms/step - accuracy: 0.4694 - loss: 2.4428 - val_accuracy: 0.6825 - val_loss: 2.3799\n","Epoch 7/50\n","50/50 - 0s - 6ms/step - accuracy: 0.5419 - loss: 2.2476 - val_accuracy: 0.7500 - val_loss: 2.0515\n","Epoch 8/50\n","50/50 - 0s - 4ms/step - accuracy: 0.6069 - loss: 2.0516 - val_accuracy: 0.7925 - val_loss: 1.7479\n","Epoch 9/50\n","50/50 - 0s - 5ms/step - accuracy: 0.6625 - loss: 1.8694 - val_accuracy: 0.8300 - val_loss: 1.5301\n","Epoch 10/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7194 - loss: 1.6994 - val_accuracy: 0.8925 - val_loss: 1.3323\n","Epoch 11/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7631 - loss: 1.5257 - val_accuracy: 0.8950 - val_loss: 1.1549\n","Epoch 12/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7969 - loss: 1.4190 - val_accuracy: 0.9000 - val_loss: 1.0579\n","Epoch 13/50\n","50/50 - 0s - 4ms/step - accuracy: 0.8306 - loss: 1.2681 - val_accuracy: 0.9100 - val_loss: 0.9462\n","Epoch 14/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8331 - loss: 1.1872 - val_accuracy: 0.9375 - val_loss: 0.8712\n","Epoch 15/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8619 - loss: 1.0837 - val_accuracy: 0.9225 - val_loss: 0.7954\n","Epoch 16/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8731 - loss: 1.0057 - val_accuracy: 0.9300 - val_loss: 0.7274\n","Epoch 17/50\n","50/50 - 0s - 7ms/step - accuracy: 0.8706 - loss: 0.9596 - val_accuracy: 0.9350 - val_loss: 0.6690\n","Epoch 18/50\n","50/50 - 0s - 3ms/step - accuracy: 0.8844 - loss: 0.8728 - val_accuracy: 0.9325 - val_loss: 0.6254\n","Epoch 19/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9019 - loss: 0.7932 - val_accuracy: 0.9450 - val_loss: 0.5648\n","Epoch 20/50\n","50/50 - 0s - 7ms/step - accuracy: 0.9187 - loss: 0.7357 - val_accuracy: 0.9475 - val_loss: 0.5228\n","Epoch 21/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9087 - loss: 0.6996 - val_accuracy: 0.9450 - val_loss: 0.4969\n","Epoch 22/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9169 - loss: 0.6875 - val_accuracy: 0.9450 - val_loss: 0.4797\n","Epoch 23/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9281 - loss: 0.6127 - val_accuracy: 0.9450 - val_loss: 0.4676\n","Epoch 24/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9287 - loss: 0.5890 - val_accuracy: 0.9475 - val_loss: 0.4452\n","Epoch 25/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9281 - loss: 0.5495 - val_accuracy: 0.9500 - val_loss: 0.4423\n","Epoch 26/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9381 - loss: 0.5131 - val_accuracy: 0.9475 - val_loss: 0.4056\n","Epoch 27/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9481 - loss: 0.4883 - val_accuracy: 0.9500 - val_loss: 0.3875\n","Epoch 28/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9531 - loss: 0.4538 - val_accuracy: 0.9500 - val_loss: 0.3799\n","Epoch 29/50\n","50/50 - 0s - 7ms/step - accuracy: 0.9606 - loss: 0.4302 - val_accuracy: 0.9525 - val_loss: 0.3515\n","Epoch 30/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9556 - loss: 0.4133 - val_accuracy: 0.9525 - val_loss: 0.3407\n","Epoch 31/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9600 - loss: 0.4081 - val_accuracy: 0.9675 - val_loss: 0.3237\n","Epoch 32/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9569 - loss: 0.3804 - val_accuracy: 0.9575 - val_loss: 0.3127\n","Epoch 33/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9625 - loss: 0.3606 - val_accuracy: 0.9625 - val_loss: 0.3090\n","Epoch 34/50\n","50/50 - 0s - 7ms/step - accuracy: 0.9619 - loss: 0.3479 - val_accuracy: 0.9575 - val_loss: 0.3041\n","Epoch 35/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9675 - loss: 0.3359 - val_accuracy: 0.9600 - val_loss: 0.3010\n","Epoch 36/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9663 - loss: 0.3303 - val_accuracy: 0.9575 - val_loss: 0.2854\n","Epoch 37/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9737 - loss: 0.3146 - val_accuracy: 0.9600 - val_loss: 0.2934\n","Epoch 38/50\n","50/50 - 0s - 7ms/step - accuracy: 0.9737 - loss: 0.3088 - val_accuracy: 0.9600 - val_loss: 0.2827\n","Epoch 39/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9731 - loss: 0.2866 - val_accuracy: 0.9575 - val_loss: 0.2698\n","Epoch 40/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9750 - loss: 0.2845 - val_accuracy: 0.9725 - val_loss: 0.2563\n","Epoch 41/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9806 - loss: 0.2697 - val_accuracy: 0.9700 - val_loss: 0.2518\n","Epoch 42/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9800 - loss: 0.2559 - val_accuracy: 0.9650 - val_loss: 0.2527\n","Epoch 43/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9775 - loss: 0.2598 - val_accuracy: 0.9625 - val_loss: 0.2461\n","Epoch 44/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9825 - loss: 0.2345 - val_accuracy: 0.9675 - val_loss: 0.2418\n","Epoch 45/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9831 - loss: 0.2313 - val_accuracy: 0.9575 - val_loss: 0.2433\n","Epoch 46/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9781 - loss: 0.2371 - val_accuracy: 0.9575 - val_loss: 0.2559\n","Epoch 47/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9831 - loss: 0.2254 - val_accuracy: 0.9600 - val_loss: 0.2538\n","Epoch 48/50\n","50/50 - 0s - 7ms/step - accuracy: 0.9806 - loss: 0.2329 - val_accuracy: 0.9600 - val_loss: 0.2365\n","Epoch 49/50\n","50/50 - 0s - 7ms/step - accuracy: 0.9869 - loss: 0.2101 - val_accuracy: 0.9650 - val_loss: 0.2332\n","Epoch 50/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9819 - loss: 0.2137 - val_accuracy: 0.9600 - val_loss: 0.2384\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n","Fold 2 - Test Accuracy: 0.9600\n","Fold 2 - Test F1-Score: 0.9600\n","Model for fold 2 saved.\n","Training on fold 3...\n","Epoch 1/50\n","50/50 - 7s - 138ms/step - accuracy: 0.0406 - loss: 4.2317 - val_accuracy: 0.0400 - val_loss: 3.9082\n","Epoch 2/50\n","50/50 - 1s - 16ms/step - accuracy: 0.0975 - loss: 3.7050 - val_accuracy: 0.2375 - val_loss: 3.6896\n","Epoch 3/50\n","50/50 - 0s - 5ms/step - accuracy: 0.1994 - loss: 3.2694 - val_accuracy: 0.4050 - val_loss: 3.3468\n","Epoch 4/50\n","50/50 - 0s - 4ms/step - accuracy: 0.3169 - loss: 2.9444 - val_accuracy: 0.5750 - val_loss: 2.9007\n","Epoch 5/50\n","50/50 - 0s - 3ms/step - accuracy: 0.4087 - loss: 2.6658 - val_accuracy: 0.6575 - val_loss: 2.5080\n","Epoch 6/50\n","50/50 - 0s - 3ms/step - accuracy: 0.4938 - loss: 2.3925 - val_accuracy: 0.7300 - val_loss: 2.1893\n","Epoch 7/50\n","50/50 - 0s - 7ms/step - accuracy: 0.5681 - loss: 2.1933 - val_accuracy: 0.7625 - val_loss: 1.8773\n","Epoch 8/50\n","50/50 - 0s - 5ms/step - accuracy: 0.6075 - loss: 2.0249 - val_accuracy: 0.8000 - val_loss: 1.6130\n","Epoch 9/50\n","50/50 - 0s - 3ms/step - accuracy: 0.6769 - loss: 1.8284 - val_accuracy: 0.8200 - val_loss: 1.4057\n","Epoch 10/50\n","50/50 - 0s - 3ms/step - accuracy: 0.7244 - loss: 1.6689 - val_accuracy: 0.8450 - val_loss: 1.2514\n","Epoch 11/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7788 - loss: 1.5176 - val_accuracy: 0.8525 - val_loss: 1.1241\n","Epoch 12/50\n","50/50 - 0s - 4ms/step - accuracy: 0.7825 - loss: 1.4409 - val_accuracy: 0.8650 - val_loss: 1.0279\n","Epoch 13/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8138 - loss: 1.2580 - val_accuracy: 0.8825 - val_loss: 0.9499\n","Epoch 14/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8494 - loss: 1.1702 - val_accuracy: 0.8875 - val_loss: 0.8583\n","Epoch 15/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8512 - loss: 1.0995 - val_accuracy: 0.8825 - val_loss: 0.7994\n","Epoch 16/50\n","50/50 - 0s - 5ms/step - accuracy: 0.8725 - loss: 0.9982 - val_accuracy: 0.9025 - val_loss: 0.7436\n","Epoch 17/50\n","50/50 - 0s - 5ms/step - accuracy: 0.8900 - loss: 0.9112 - val_accuracy: 0.9150 - val_loss: 0.7036\n","Epoch 18/50\n","50/50 - 0s - 5ms/step - accuracy: 0.8925 - loss: 0.8630 - val_accuracy: 0.9225 - val_loss: 0.6466\n","Epoch 19/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9100 - loss: 0.7711 - val_accuracy: 0.9200 - val_loss: 0.6149\n","Epoch 20/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9150 - loss: 0.7397 - val_accuracy: 0.9250 - val_loss: 0.5651\n","Epoch 21/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9212 - loss: 0.6969 - val_accuracy: 0.9225 - val_loss: 0.5514\n","Epoch 22/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9225 - loss: 0.6602 - val_accuracy: 0.9075 - val_loss: 0.5327\n","Epoch 23/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9294 - loss: 0.6000 - val_accuracy: 0.9150 - val_loss: 0.5012\n","Epoch 24/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9388 - loss: 0.5741 - val_accuracy: 0.9225 - val_loss: 0.4688\n","Epoch 25/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9438 - loss: 0.5232 - val_accuracy: 0.9250 - val_loss: 0.4524\n","Epoch 26/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9488 - loss: 0.5126 - val_accuracy: 0.9300 - val_loss: 0.4320\n","Epoch 27/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9581 - loss: 0.4640 - val_accuracy: 0.9175 - val_loss: 0.4305\n","Epoch 28/50\n","50/50 - 0s - 7ms/step - accuracy: 0.9569 - loss: 0.4285 - val_accuracy: 0.9225 - val_loss: 0.4139\n","Epoch 29/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9531 - loss: 0.4454 - val_accuracy: 0.9400 - val_loss: 0.3955\n","Epoch 30/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9556 - loss: 0.4080 - val_accuracy: 0.9275 - val_loss: 0.3952\n","Epoch 31/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9606 - loss: 0.3886 - val_accuracy: 0.9325 - val_loss: 0.3963\n","Epoch 32/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9625 - loss: 0.3620 - val_accuracy: 0.9350 - val_loss: 0.3733\n","Epoch 33/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9725 - loss: 0.3465 - val_accuracy: 0.9325 - val_loss: 0.3837\n","Epoch 34/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9681 - loss: 0.3454 - val_accuracy: 0.9350 - val_loss: 0.3723\n","Epoch 35/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9750 - loss: 0.3199 - val_accuracy: 0.9250 - val_loss: 0.3731\n","Epoch 36/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9762 - loss: 0.2966 - val_accuracy: 0.9325 - val_loss: 0.3644\n","Epoch 37/50\n","50/50 - 0s - 7ms/step - accuracy: 0.9794 - loss: 0.2909 - val_accuracy: 0.9375 - val_loss: 0.3669\n","Epoch 38/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9700 - loss: 0.2946 - val_accuracy: 0.9350 - val_loss: 0.3528\n","Epoch 39/50\n","50/50 - 0s - 7ms/step - accuracy: 0.9762 - loss: 0.2891 - val_accuracy: 0.9400 - val_loss: 0.3430\n","Epoch 40/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9762 - loss: 0.2785 - val_accuracy: 0.9350 - val_loss: 0.3481\n","Epoch 41/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9819 - loss: 0.2472 - val_accuracy: 0.9350 - val_loss: 0.3396\n","Epoch 42/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9862 - loss: 0.2478 - val_accuracy: 0.9400 - val_loss: 0.3340\n","Epoch 43/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9831 - loss: 0.2373 - val_accuracy: 0.9325 - val_loss: 0.3361\n","Epoch 44/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9781 - loss: 0.2347 - val_accuracy: 0.9425 - val_loss: 0.3393\n","Epoch 45/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9862 - loss: 0.2250 - val_accuracy: 0.9425 - val_loss: 0.3361\n","Epoch 46/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9875 - loss: 0.2132 - val_accuracy: 0.9475 - val_loss: 0.3292\n","Epoch 47/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9850 - loss: 0.2166 - val_accuracy: 0.9450 - val_loss: 0.3290\n","Epoch 48/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9825 - loss: 0.2081 - val_accuracy: 0.9375 - val_loss: 0.3225\n","Epoch 49/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9887 - loss: 0.1967 - val_accuracy: 0.9375 - val_loss: 0.3343\n","Epoch 50/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9844 - loss: 0.2047 - val_accuracy: 0.9375 - val_loss: 0.3261\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n","Fold 3 - Test Accuracy: 0.9375\n","Fold 3 - Test F1-Score: 0.9374\n","Model for fold 3 saved.\n","Training on fold 4...\n","Epoch 1/50\n","50/50 - 8s - 162ms/step - accuracy: 0.0400 - loss: 4.3393 - val_accuracy: 0.0550 - val_loss: 3.9105\n","Epoch 2/50\n","50/50 - 5s - 103ms/step - accuracy: 0.0675 - loss: 3.8117 - val_accuracy: 0.1400 - val_loss: 3.7267\n","Epoch 3/50\n","50/50 - 0s - 5ms/step - accuracy: 0.1406 - loss: 3.4070 - val_accuracy: 0.2725 - val_loss: 3.4119\n","Epoch 4/50\n","50/50 - 0s - 7ms/step - accuracy: 0.2200 - loss: 3.0462 - val_accuracy: 0.4400 - val_loss: 2.9918\n","Epoch 5/50\n","50/50 - 0s - 4ms/step - accuracy: 0.3575 - loss: 2.7199 - val_accuracy: 0.6125 - val_loss: 2.5321\n","Epoch 6/50\n","50/50 - 0s - 6ms/step - accuracy: 0.4669 - loss: 2.4418 - val_accuracy: 0.7250 - val_loss: 2.1472\n","Epoch 7/50\n","50/50 - 0s - 3ms/step - accuracy: 0.5650 - loss: 2.2002 - val_accuracy: 0.7925 - val_loss: 1.7863\n","Epoch 8/50\n","50/50 - 0s - 7ms/step - accuracy: 0.6263 - loss: 1.9947 - val_accuracy: 0.8525 - val_loss: 1.5136\n","Epoch 9/50\n","50/50 - 0s - 6ms/step - accuracy: 0.6831 - loss: 1.8147 - val_accuracy: 0.8550 - val_loss: 1.3157\n","Epoch 10/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7256 - loss: 1.6538 - val_accuracy: 0.8725 - val_loss: 1.1744\n","Epoch 11/50\n","50/50 - 0s - 5ms/step - accuracy: 0.7487 - loss: 1.5432 - val_accuracy: 0.8725 - val_loss: 1.0360\n","Epoch 12/50\n","50/50 - 0s - 5ms/step - accuracy: 0.7994 - loss: 1.3574 - val_accuracy: 0.8900 - val_loss: 0.9046\n","Epoch 13/50\n","50/50 - 0s - 5ms/step - accuracy: 0.8250 - loss: 1.2690 - val_accuracy: 0.8975 - val_loss: 0.8449\n","Epoch 14/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8263 - loss: 1.1927 - val_accuracy: 0.8975 - val_loss: 0.7518\n","Epoch 15/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8481 - loss: 1.0696 - val_accuracy: 0.9100 - val_loss: 0.6836\n","Epoch 16/50\n","50/50 - 0s - 5ms/step - accuracy: 0.8806 - loss: 0.9646 - val_accuracy: 0.9150 - val_loss: 0.6204\n","Epoch 17/50\n","50/50 - 0s - 7ms/step - accuracy: 0.8856 - loss: 0.9061 - val_accuracy: 0.9225 - val_loss: 0.5804\n","Epoch 18/50\n","50/50 - 0s - 4ms/step - accuracy: 0.8800 - loss: 0.8576 - val_accuracy: 0.9300 - val_loss: 0.6022\n","Epoch 19/50\n","50/50 - 0s - 7ms/step - accuracy: 0.8956 - loss: 0.8100 - val_accuracy: 0.9350 - val_loss: 0.5289\n","Epoch 20/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9137 - loss: 0.7300 - val_accuracy: 0.9375 - val_loss: 0.4885\n","Epoch 21/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9056 - loss: 0.7051 - val_accuracy: 0.9475 - val_loss: 0.4509\n","Epoch 22/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9287 - loss: 0.6285 - val_accuracy: 0.9475 - val_loss: 0.4344\n","Epoch 23/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9262 - loss: 0.6184 - val_accuracy: 0.9350 - val_loss: 0.4058\n","Epoch 24/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9281 - loss: 0.5695 - val_accuracy: 0.9325 - val_loss: 0.3861\n","Epoch 25/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9337 - loss: 0.5388 - val_accuracy: 0.9475 - val_loss: 0.3567\n","Epoch 26/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9362 - loss: 0.5246 - val_accuracy: 0.9425 - val_loss: 0.3548\n","Epoch 27/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9488 - loss: 0.4938 - val_accuracy: 0.9400 - val_loss: 0.3453\n","Epoch 28/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9413 - loss: 0.4673 - val_accuracy: 0.9450 - val_loss: 0.3294\n","Epoch 29/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9494 - loss: 0.4450 - val_accuracy: 0.9450 - val_loss: 0.3134\n","Epoch 30/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9563 - loss: 0.4055 - val_accuracy: 0.9525 - val_loss: 0.3048\n","Epoch 31/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9594 - loss: 0.3914 - val_accuracy: 0.9500 - val_loss: 0.3050\n","Epoch 32/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9619 - loss: 0.3935 - val_accuracy: 0.9550 - val_loss: 0.2994\n","Epoch 33/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9631 - loss: 0.3676 - val_accuracy: 0.9550 - val_loss: 0.2876\n","Epoch 34/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9569 - loss: 0.3627 - val_accuracy: 0.9525 - val_loss: 0.2682\n","Epoch 35/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9600 - loss: 0.3397 - val_accuracy: 0.9500 - val_loss: 0.2669\n","Epoch 36/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9638 - loss: 0.3245 - val_accuracy: 0.9600 - val_loss: 0.2595\n","Epoch 37/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9644 - loss: 0.3181 - val_accuracy: 0.9550 - val_loss: 0.2608\n","Epoch 38/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9725 - loss: 0.3042 - val_accuracy: 0.9550 - val_loss: 0.2578\n","Epoch 39/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9750 - loss: 0.2913 - val_accuracy: 0.9525 - val_loss: 0.2537\n","Epoch 40/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9750 - loss: 0.2735 - val_accuracy: 0.9550 - val_loss: 0.2492\n","Epoch 41/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9744 - loss: 0.2576 - val_accuracy: 0.9550 - val_loss: 0.2478\n","Epoch 42/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9775 - loss: 0.2605 - val_accuracy: 0.9500 - val_loss: 0.2511\n","Epoch 43/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9831 - loss: 0.2416 - val_accuracy: 0.9600 - val_loss: 0.2419\n","Epoch 44/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9812 - loss: 0.2320 - val_accuracy: 0.9600 - val_loss: 0.2398\n","Epoch 45/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9800 - loss: 0.2407 - val_accuracy: 0.9650 - val_loss: 0.2421\n","Epoch 46/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9831 - loss: 0.2283 - val_accuracy: 0.9575 - val_loss: 0.2311\n","Epoch 47/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9837 - loss: 0.2144 - val_accuracy: 0.9625 - val_loss: 0.2404\n","Epoch 48/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9812 - loss: 0.2255 - val_accuracy: 0.9625 - val_loss: 0.2309\n","Epoch 49/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9825 - loss: 0.2218 - val_accuracy: 0.9575 - val_loss: 0.2372\n","Epoch 50/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9856 - loss: 0.1961 - val_accuracy: 0.9600 - val_loss: 0.2303\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n","Fold 4 - Test Accuracy: 0.9600\n","Fold 4 - Test F1-Score: 0.9602\n","Model for fold 4 saved.\n","Training on fold 5...\n","Epoch 1/50\n","50/50 - 8s - 159ms/step - accuracy: 0.0331 - loss: 4.2114 - val_accuracy: 0.0400 - val_loss: 3.9241\n","Epoch 2/50\n","50/50 - 5s - 103ms/step - accuracy: 0.0856 - loss: 3.6944 - val_accuracy: 0.2000 - val_loss: 3.7092\n","Epoch 3/50\n","50/50 - 0s - 6ms/step - accuracy: 0.1881 - loss: 3.2827 - val_accuracy: 0.4050 - val_loss: 3.4240\n","Epoch 4/50\n","50/50 - 0s - 7ms/step - accuracy: 0.3137 - loss: 2.8784 - val_accuracy: 0.5550 - val_loss: 3.0822\n","Epoch 5/50\n","50/50 - 0s - 5ms/step - accuracy: 0.4212 - loss: 2.6074 - val_accuracy: 0.6550 - val_loss: 2.6724\n","Epoch 6/50\n","50/50 - 0s - 6ms/step - accuracy: 0.5019 - loss: 2.3572 - val_accuracy: 0.7100 - val_loss: 2.2791\n","Epoch 7/50\n","50/50 - 0s - 5ms/step - accuracy: 0.5975 - loss: 2.1115 - val_accuracy: 0.7750 - val_loss: 1.9074\n","Epoch 8/50\n","50/50 - 0s - 5ms/step - accuracy: 0.6456 - loss: 1.9288 - val_accuracy: 0.8075 - val_loss: 1.6531\n","Epoch 9/50\n","50/50 - 0s - 6ms/step - accuracy: 0.7194 - loss: 1.7349 - val_accuracy: 0.8150 - val_loss: 1.4864\n","Epoch 10/50\n","50/50 - 0s - 5ms/step - accuracy: 0.7625 - loss: 1.5679 - val_accuracy: 0.8325 - val_loss: 1.3095\n","Epoch 11/50\n","50/50 - 0s - 5ms/step - accuracy: 0.7875 - loss: 1.4275 - val_accuracy: 0.8325 - val_loss: 1.1799\n","Epoch 12/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8181 - loss: 1.3190 - val_accuracy: 0.8300 - val_loss: 1.0661\n","Epoch 13/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8375 - loss: 1.2084 - val_accuracy: 0.8375 - val_loss: 0.9879\n","Epoch 14/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8425 - loss: 1.1200 - val_accuracy: 0.8425 - val_loss: 0.9163\n","Epoch 15/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8756 - loss: 1.0145 - val_accuracy: 0.8600 - val_loss: 0.8632\n","Epoch 16/50\n","50/50 - 0s - 6ms/step - accuracy: 0.8763 - loss: 0.9549 - val_accuracy: 0.8600 - val_loss: 0.8116\n","Epoch 17/50\n","50/50 - 0s - 5ms/step - accuracy: 0.8894 - loss: 0.8765 - val_accuracy: 0.8625 - val_loss: 0.7598\n","Epoch 18/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9069 - loss: 0.7895 - val_accuracy: 0.8625 - val_loss: 0.7248\n","Epoch 19/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9062 - loss: 0.7582 - val_accuracy: 0.8625 - val_loss: 0.6626\n","Epoch 20/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9362 - loss: 0.6857 - val_accuracy: 0.8725 - val_loss: 0.6438\n","Epoch 21/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9231 - loss: 0.6670 - val_accuracy: 0.8850 - val_loss: 0.6176\n","Epoch 22/50\n","50/50 - 0s - 7ms/step - accuracy: 0.9244 - loss: 0.6227 - val_accuracy: 0.8800 - val_loss: 0.5908\n","Epoch 23/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9413 - loss: 0.5688 - val_accuracy: 0.8775 - val_loss: 0.5688\n","Epoch 24/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9475 - loss: 0.5325 - val_accuracy: 0.8850 - val_loss: 0.5563\n","Epoch 25/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9475 - loss: 0.5133 - val_accuracy: 0.8850 - val_loss: 0.5388\n","Epoch 26/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9463 - loss: 0.4684 - val_accuracy: 0.8875 - val_loss: 0.5371\n","Epoch 27/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9594 - loss: 0.4346 - val_accuracy: 0.8900 - val_loss: 0.5214\n","Epoch 28/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9469 - loss: 0.4256 - val_accuracy: 0.8925 - val_loss: 0.5062\n","Epoch 29/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9619 - loss: 0.3992 - val_accuracy: 0.8925 - val_loss: 0.4865\n","Epoch 30/50\n","50/50 - 0s - 7ms/step - accuracy: 0.9594 - loss: 0.4044 - val_accuracy: 0.8900 - val_loss: 0.4924\n","Epoch 31/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9600 - loss: 0.3722 - val_accuracy: 0.8950 - val_loss: 0.4653\n","Epoch 32/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9613 - loss: 0.3526 - val_accuracy: 0.8975 - val_loss: 0.4492\n","Epoch 33/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9700 - loss: 0.3222 - val_accuracy: 0.8850 - val_loss: 0.4569\n","Epoch 34/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9719 - loss: 0.3318 - val_accuracy: 0.8925 - val_loss: 0.4656\n","Epoch 35/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9681 - loss: 0.3073 - val_accuracy: 0.9025 - val_loss: 0.4433\n","Epoch 36/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9756 - loss: 0.3101 - val_accuracy: 0.9000 - val_loss: 0.4439\n","Epoch 37/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9756 - loss: 0.2860 - val_accuracy: 0.9075 - val_loss: 0.4349\n","Epoch 38/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9800 - loss: 0.2726 - val_accuracy: 0.9100 - val_loss: 0.4257\n","Epoch 39/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9769 - loss: 0.2649 - val_accuracy: 0.9100 - val_loss: 0.4362\n","Epoch 40/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9812 - loss: 0.2573 - val_accuracy: 0.9050 - val_loss: 0.4457\n","Epoch 41/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9806 - loss: 0.2364 - val_accuracy: 0.9100 - val_loss: 0.4216\n","Epoch 42/50\n","50/50 - 0s - 3ms/step - accuracy: 0.9787 - loss: 0.2427 - val_accuracy: 0.9000 - val_loss: 0.4200\n","Epoch 43/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9837 - loss: 0.2392 - val_accuracy: 0.8975 - val_loss: 0.4280\n","Epoch 44/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9850 - loss: 0.2219 - val_accuracy: 0.9025 - val_loss: 0.4262\n","Epoch 45/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9825 - loss: 0.2210 - val_accuracy: 0.9000 - val_loss: 0.4250\n","Epoch 46/50\n","50/50 - 0s - 5ms/step - accuracy: 0.9844 - loss: 0.2210 - val_accuracy: 0.9050 - val_loss: 0.4277\n","Epoch 47/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9862 - loss: 0.2101 - val_accuracy: 0.9125 - val_loss: 0.4272\n","Epoch 48/50\n","50/50 - 0s - 6ms/step - accuracy: 0.9806 - loss: 0.2260 - val_accuracy: 0.9050 - val_loss: 0.4221\n","Epoch 49/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9850 - loss: 0.1984 - val_accuracy: 0.9050 - val_loss: 0.4191\n","Epoch 50/50\n","50/50 - 0s - 4ms/step - accuracy: 0.9912 - loss: 0.1849 - val_accuracy: 0.9100 - val_loss: 0.4122\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step\n","Fold 5 - Test Accuracy: 0.9100\n","Fold 5 - Test F1-Score: 0.9023\n","Model for fold 5 saved.\n","\n","AST FCNN Evaluation Results:\n","Mean Accuracy: 0.9415 ± 0.0184\n","Mean F1-Score: 0.9398 ± 0.0212\n"]}]},{"cell_type":"code","source":["# Scaricare i modelli per i 5 fold\n","!gdown 11hhTBJZpf-BRFjWhuFfrO5mJCIfpKXr6 -O ast_fcnn_folds.zip\n","\n","# Estrarre i file\n","!unzip ast_fcnn_folds.zip\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4piWR4gkroa6","executionInfo":{"status":"ok","timestamp":1735379626101,"user_tz":-60,"elapsed":6662,"user":{"displayName":"Julius Maliwat","userId":"06100578401494245092"}},"outputId":"cc410025-4fb5-4dce-f2e9-ff21d8c9d26f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=11hhTBJZpf-BRFjWhuFfrO5mJCIfpKXr6\n","From (redirected): https://drive.google.com/uc?id=11hhTBJZpf-BRFjWhuFfrO5mJCIfpKXr6&confirm=t&uuid=50b91475-dcef-430c-b21a-ecb3fa0b5fd0\n","To: /content/ast_fcnn_folds.zip\n","100% 31.9M/31.9M [00:00<00:00, 32.2MB/s]\n","Archive:  ast_fcnn_folds.zip\n","  inflating: ast_fcnn_fold_1_embeddings.keras  \n","  inflating: ast_fcnn_fold_2_embeddings.keras  \n","  inflating: ast_fcnn_fold_3_embeddings.keras  \n","  inflating: ast_fcnn_fold_4_embeddings.keras  \n","  inflating: ast_fcnn_fold_5_embeddings.keras  \n"]}]},{"cell_type":"code","source":["# Scaricare il CSV in formato raw dal repository GitHub\n","!wget https://raw.githubusercontent.com/karolpiczak/ESC-50/master/meta/esc50.csv -O esc50.csv\n","import pandas as pd\n","\n","metadata = pd.read_csv(\"esc50.csv\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3nEDHNaxsKWu","executionInfo":{"status":"ok","timestamp":1735379703827,"user_tz":-60,"elapsed":483,"user":{"displayName":"Julius Maliwat","userId":"06100578401494245092"}},"outputId":"fffcfa10-7bc4-4951-9f26-73caa39de94d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-12-28 09:54:47--  https://raw.githubusercontent.com/karolpiczak/ESC-50/master/meta/esc50.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 93742 (92K) [text/plain]\n","Saving to: ‘esc50.csv’\n","\n","esc50.csv           100%[===================>]  91.54K  --.-KB/s    in 0.02s   \n","\n","2024-12-28 09:54:48 (5.57 MB/s) - ‘esc50.csv’ saved [93742/93742]\n","\n"]}]},{"cell_type":"code","source":["# Creare un dizionario di mappatura {target: category}\n","target_to_category = dict(zip(metadata['target'], metadata['category']))\n"],"metadata":{"id":"A-nfBxXhsPH1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import classification_report\n","from tensorflow.keras.models import load_model\n","\n","# Supponiamo che i file estratti abbiano questi nomi\n","model_paths = [\n","    \"ast_fcnn_fold_1_embeddings.keras\",\n","    \"ast_fcnn_fold_2_embeddings.keras\",\n","    \"ast_fcnn_fold_3_embeddings.keras\",\n","    \"ast_fcnn_fold_4_embeddings.keras\",\n","    \"ast_fcnn_fold_5_embeddings.keras\"\n","]\n","\n","# Array per memorizzare le predizioni\n","y_true = []\n","y_pred = []\n","\n","# Predefined folds (ast_folds indica il fold di ciascun campione)\n","for fold, model_path in enumerate(model_paths, start=1):\n","    print(f\"Evaluating fold {fold}...\")\n","\n","    # Caricare il modello del fold corrente\n","    model = load_model(model_path)\n","\n","    # Selezionare i dati per il fold corrente\n","    train_indices = ast_folds != fold\n","    test_indices = ast_folds == fold\n","\n","    X_train, X_test = ast_embeddings[train_indices], ast_embeddings[test_indices]\n","    y_train, y_test = ast_labels[train_indices], ast_labels[test_indices]\n","\n","    # Memorizzare i veri valori di y\n","    y_true.extend(y_test)\n","\n","    # Predire le classi per il test set\n","    fold_predictions = model.predict(X_test).argmax(axis=1)\n","    y_pred.extend(fold_predictions)\n","\n","    print(f\"Fold {fold} completed.\")\n","\n","# Convertire le liste in array\n","y_true = np.array(y_true)\n","y_pred = np.array(y_pred)\n","\n","# Convertire i label numerici in categorie usando il dizionario\n","y_true_categories = [target_to_category[label] for label in y_true]\n","y_pred_categories = [target_to_category[label] for label in y_pred]\n","\n","# Generare il classification report usando i nomi delle categorie\n","print(\"Classification Report:\")\n","print(classification_report(y_true_categories, y_pred_categories))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GlMhOMsyrqW-","executionInfo":{"status":"ok","timestamp":1735379726270,"user_tz":-60,"elapsed":5931,"user":{"displayName":"Julius Maliwat","userId":"06100578401494245092"}},"outputId":"5f4d850a-e314-4605-fd39-2facae5e8df1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluating fold 1...\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n","Fold 1 completed.\n","Evaluating fold 2...\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n","Fold 2 completed.\n","Evaluating fold 3...\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","Fold 3 completed.\n","Evaluating fold 4...\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Fold 4 completed.\n","Evaluating fold 5...\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n","Fold 5 completed.\n","Classification Report:\n","                  precision    recall  f1-score   support\n","\n","        airplane       0.82      0.82      0.82        40\n","       breathing       1.00      0.93      0.96        40\n","  brushing_teeth       0.98      1.00      0.99        40\n","     can_opening       0.95      0.93      0.94        40\n","        car_horn       0.95      0.97      0.96        40\n","             cat       1.00      0.97      0.99        40\n","        chainsaw       0.90      0.90      0.90        40\n","  chirping_birds       1.00      0.97      0.99        40\n","    church_bells       1.00      0.97      0.99        40\n","        clapping       0.95      1.00      0.98        40\n","     clock_alarm       0.97      0.97      0.97        40\n","      clock_tick       0.97      0.95      0.96        40\n","        coughing       0.88      0.88      0.88        40\n","             cow       1.00      0.95      0.97        40\n","  crackling_fire       0.88      0.95      0.92        40\n","        crickets       0.97      0.93      0.95        40\n","            crow       1.00      1.00      1.00        40\n","     crying_baby       0.93      0.95      0.94        40\n","             dog       1.00      1.00      1.00        40\n","door_wood_creaks       0.97      0.93      0.95        40\n"," door_wood_knock       0.91      0.97      0.94        40\n","drinking_sipping       0.89      0.97      0.93        40\n","          engine       0.74      0.88      0.80        40\n","       fireworks       0.95      0.88      0.91        40\n","       footsteps       0.97      0.80      0.88        40\n","            frog       1.00      1.00      1.00        40\n","  glass_breaking       0.95      0.97      0.96        40\n","        hand_saw       1.00      0.95      0.97        40\n","      helicopter       0.82      0.70      0.76        40\n","             hen       1.00      0.97      0.99        40\n","         insects       0.95      1.00      0.98        40\n"," keyboard_typing       0.90      0.95      0.93        40\n","        laughing       0.89      0.85      0.87        40\n","     mouse_click       0.90      0.88      0.89        40\n","             pig       0.95      0.97      0.96        40\n","   pouring_water       0.98      1.00      0.99        40\n","            rain       1.00      0.95      0.97        40\n","         rooster       1.00      1.00      1.00        40\n","       sea_waves       0.93      1.00      0.96        40\n","           sheep       0.97      0.97      0.97        40\n","           siren       1.00      0.97      0.99        40\n","        sneezing       0.93      0.93      0.93        40\n","         snoring       0.93      1.00      0.96        40\n","    thunderstorm       0.95      1.00      0.98        40\n","    toilet_flush       1.00      1.00      1.00        40\n","           train       0.95      0.97      0.96        40\n","  vacuum_cleaner       0.95      0.97      0.96        40\n"," washing_machine       0.77      0.82      0.80        40\n","     water_drops       0.90      0.90      0.90        40\n","            wind       0.92      0.85      0.88        40\n","\n","        accuracy                           0.94      2000\n","       macro avg       0.94      0.94      0.94      2000\n","    weighted avg       0.94      0.94      0.94      2000\n","\n"]}]}]}